About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 4 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 416
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 4 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 416
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 4 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 416
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 4 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 416
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 4 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 416
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 50.124007936507944%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 50.124007936507944%| LR: 0.005

About to train 4 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 416
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 64.21626984126983% | Avg. reward: -771.1666666666666 | Avg. normalized reward: -14.280864197530864 | Avg. agents in deadlock: 14.98015873015873%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 64.21626984126983% | Avg. reward: -771.1666666666666 | Avg. normalized reward: -14.280864197530864 | Avg. agents in deadlock: 14.98015873015873%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 34.06746031746032% | Avg. reward: -1550.3333333333333 | Avg. normalized reward: -28.709876543209877 | Avg. agents in deadlock: 39.55853174603175%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 34.06746031746032% | Avg. reward: -1550.3333333333333 | Avg. normalized reward: -28.709876543209877 | Avg. agents in deadlock: 39.55853174603175%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 6.299603174603174% | Avg. reward: -1719.1666666666667 | Avg. normalized reward: -31.83641975308642 | Avg. agents in deadlock: 58.28373015873015%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 6.299603174603174% | Avg. reward: -1719.1666666666667 | Avg. normalized reward: -31.83641975308642 | Avg. agents in deadlock: 58.28373015873015%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 53.52182539682539%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 6.721230158730158% | Avg. reward: -1716.625 | Avg. normalized reward: -31.78935185185185 | Avg. agents in deadlock: 62.5%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 13.566468253968253% | Avg. reward: -1601.4583333333333 | Avg. normalized reward: -29.656635802469136 | Avg. agents in deadlock: 56.25992063492063%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 13.566468253968253% | Avg. reward: -1601.4583333333333 | Avg. normalized reward: -29.656635802469136 | Avg. agents in deadlock: 56.25992063492063%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 45.01984126984127% | Avg. reward: -1295.5 | Avg. normalized reward: -23.99074074074074 | Avg. agents in deadlock: 44.42460317460317%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 45.01984126984127% | Avg. reward: -1295.5 | Avg. normalized reward: -23.99074074074074 | Avg. agents in deadlock: 44.42460317460317%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 45.01984126984127% | Avg. reward: -1295.5 | Avg. normalized reward: -23.99074074074074 | Avg. agents in deadlock: 44.42460317460317%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 45.01984126984127% | Avg. reward: -1295.5 | Avg. normalized reward: -23.99074074074074 | Avg. agents in deadlock: 44.42460317460317%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 45.01984126984127% | Avg. reward: -1295.5 | Avg. normalized reward: -23.99074074074074 | Avg. agents in deadlock: 44.42460317460317%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 59.58829365079366% | Avg. reward: -892.125 | Avg. normalized reward: -16.520833333333332 | Avg. agents in deadlock: 14.285714285714285%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 35.45634920634921% | Avg. reward: -1395.5416666666667 | Avg. normalized reward: -25.843364197530864 | Avg. agents in deadlock: 31.433531746031747%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 35.45634920634921% | Avg. reward: -1395.5416666666667 | Avg. normalized reward: -25.843364197530864 | Avg. agents in deadlock: 31.433531746031747%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 38.50694444444444% | Avg. reward: -1347.5416666666667 | Avg. normalized reward: -24.954475308641978 | Avg. agents in deadlock: 43.973214285714285%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 38.50694444444444% | Avg. reward: -1347.5416666666667 | Avg. normalized reward: -24.954475308641978 | Avg. agents in deadlock: 43.973214285714285%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 38.50694444444444% | Avg. reward: -1347.5416666666667 | Avg. normalized reward: -24.954475308641978 | Avg. agents in deadlock: 43.973214285714285%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 30.803571428571423% | Avg. reward: -1443.5833333333333 | Avg. normalized reward: -26.733024691358022 | Avg. agents in deadlock: 56.69642857142857%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 30.803571428571423% | Avg. reward: -1443.5833333333333 | Avg. normalized reward: -26.733024691358022 | Avg. agents in deadlock: 56.69642857142857%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 6.884920634920634% | Avg. reward: -1716.875 | Avg. normalized reward: -31.79398148148148 | Avg. agents in deadlock: 62.286706349206355%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 42.604166666666664% | Avg. reward: -1153.1666666666667 | Avg. normalized reward: -21.35493827160494 | Avg. agents in deadlock: 22.32638888888889%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 42.604166666666664% | Avg. reward: -1153.1666666666667 | Avg. normalized reward: -21.35493827160494 | Avg. agents in deadlock: 22.32638888888889%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 68.82440476190474% | Avg. reward: -787.25 | Avg. normalized reward: -14.578703703703704 | Avg. agents in deadlock: 21.800595238095237%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 68.82440476190474% | Avg. reward: -787.25 | Avg. normalized reward: -14.578703703703704 | Avg. agents in deadlock: 21.800595238095237%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 68.82440476190474% | Avg. reward: -787.25 | Avg. normalized reward: -14.578703703703704 | Avg. agents in deadlock: 21.800595238095237%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 61.845238095238095% | Avg. reward: -983.125 | Avg. normalized reward: -18.20601851851852 | Avg. agents in deadlock: 25.178571428571434%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 51.230158730158735% | Avg. reward: -1233.6666666666667 | Avg. normalized reward: -22.84567901234568 | Avg. agents in deadlock: 24.642857142857142%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 51.230158730158735% | Avg. reward: -1233.6666666666667 | Avg. normalized reward: -22.84567901234568 | Avg. agents in deadlock: 24.642857142857142%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 30.625000000000007% | Avg. reward: -1328.2916666666667 | Avg. normalized reward: -24.597993827160494 | Avg. agents in deadlock: 45.53571428571428%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 30.625000000000007% | Avg. reward: -1328.2916666666667 | Avg. normalized reward: -24.597993827160494 | Avg. agents in deadlock: 45.53571428571428%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 63.07539682539682% | Avg. reward: -933.125 | Avg. normalized reward: -17.28009259259259 | Avg. agents in deadlock: 16.974206349206348%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 63.07539682539682% | Avg. reward: -933.125 | Avg. normalized reward: -17.28009259259259 | Avg. agents in deadlock: 16.974206349206348%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 63.07539682539682% | Avg. reward: -933.125 | Avg. normalized reward: -17.28009259259259 | Avg. agents in deadlock: 16.974206349206348%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 63.07539682539682% | Avg. reward: -933.125 | Avg. normalized reward: -17.28009259259259 | Avg. agents in deadlock: 16.974206349206348%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 31.52281746031746% | Avg. reward: -1343.2916666666667 | Avg. normalized reward: -24.875771604938272 | Avg. agents in deadlock: 47.99107142857142%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 31.52281746031746% | Avg. reward: -1343.2916666666667 | Avg. normalized reward: -24.875771604938272 | Avg. agents in deadlock: 47.99107142857142%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 4.4146825396825395% | Avg. reward: -1801.1666666666667 | Avg. normalized reward: -33.35493827160494 | Avg. agents in deadlock: 65.57043650793652%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 4.4146825396825395% | Avg. reward: -1801.1666666666667 | Avg. normalized reward: -33.35493827160494 | Avg. agents in deadlock: 65.57043650793652%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 5.109126984126983% | Avg. reward: -1783.0833333333333 | Avg. normalized reward: -33.02006172839506 | Avg. agents in deadlock: 55.37698412698413%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 35.9077380952381% | Avg. reward: -1209.7083333333333 | Avg. normalized reward: -22.402006172839506 | Avg. agents in deadlock: 19.285714285714285%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 35.9077380952381% | Avg. reward: -1209.7083333333333 | Avg. normalized reward: -22.402006172839506 | Avg. agents in deadlock: 19.285714285714285%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 41.99404761904762% | Avg. reward: -1186.3333333333333 | Avg. normalized reward: -21.969135802469136 | Avg. agents in deadlock: 48.333333333333336%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 41.99404761904762% | Avg. reward: -1186.3333333333333 | Avg. normalized reward: -21.969135802469136 | Avg. agents in deadlock: 48.333333333333336%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 41.99404761904762% | Avg. reward: -1186.3333333333333 | Avg. normalized reward: -21.969135802469136 | Avg. agents in deadlock: 48.333333333333336%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 41.99404761904762% | Avg. reward: -1186.3333333333333 | Avg. normalized reward: -21.969135802469136 | Avg. agents in deadlock: 48.333333333333336%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 41.99404761904762% | Avg. reward: -1186.3333333333333 | Avg. normalized reward: -21.969135802469136 | Avg. agents in deadlock: 48.333333333333336%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 43.05555555555555%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 21.30456349206349% | Avg. reward: -1398.2916666666667 | Avg. normalized reward: -25.89429012345679 | Avg. agents in deadlock: 15.892857142857144%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 46.88988095238094% | Avg. reward: -1186.7083333333333 | Avg. normalized reward: -21.97608024691358 | Avg. agents in deadlock: 32.82242063492063%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 46.88988095238094% | Avg. reward: -1186.7083333333333 | Avg. normalized reward: -21.97608024691358 | Avg. agents in deadlock: 32.82242063492063%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 60.89781746031747%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 32.19742063492064% | Avg. reward: -1274.375 | Avg. normalized reward: -23.599537037037038 | Avg. agents in deadlock: 34.74206349206349%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 13.963293650793648% | Avg. reward: -1669.2916666666667 | Avg. normalized reward: -30.91280864197531 | Avg. agents in deadlock: 48.541666666666664%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 10.803571428571429% | Avg. reward: -1817.2083333333333 | Avg. normalized reward: -33.652006172839506 | Avg. agents in deadlock: 12.5%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 32.06349206349206% | Avg. reward: -1558.0 | Avg. normalized reward: -28.85185185185185 | Avg. agents in deadlock: 19.270833333333336%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 57.16269841269842% | Avg. reward: -1022.25 | Avg. normalized reward: -18.930555555555557 | Avg. agents in deadlock: 26.235119047619044%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 83.33333333333334% | Avg. reward: -470.7916666666667 | Avg. normalized reward: -8.718364197530864 | Avg. agents in deadlock: 12.5%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 83.33333333333334% | Avg. reward: -470.7916666666667 | Avg. normalized reward: -8.718364197530864 | Avg. agents in deadlock: 12.5%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 83.33333333333334% | Avg. reward: -470.7916666666667 | Avg. normalized reward: -8.718364197530864 | Avg. agents in deadlock: 12.5%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 83.33333333333334% | Avg. reward: -470.7916666666667 | Avg. normalized reward: -8.718364197530864 | Avg. agents in deadlock: 12.5%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 82.14285714285715% | Avg. reward: -513.5416666666666 | Avg. normalized reward: -9.51003086419753 | Avg. agents in deadlock: 16.666666666666664%| LR: 0.005


Epoch 60, testing agents on 3: Avg. done agents: 84.6875% | Avg. reward: -447.25 | Avg. normalized reward: -8.282407407407407 | Avg. agents in deadlock: 6.979166666666667%| LR: 0.005


Epoch 70, testing agents on 3: Avg. done agents: 86.77083333333333% | Avg. reward: -451.5416666666667 | Avg. normalized reward: -8.361882716049383 | Avg. agents in deadlock: 6.979166666666667%| LR: 0.005


Epoch 80, testing agents on 3: Avg. done agents: 83.75% | Avg. reward: -504.375 | Avg. normalized reward: -9.340277777777779 | Avg. agents in deadlock: 11.041666666666664%| LR: 0.005


Epoch 90, testing agents on 3: Avg. done agents: 72.49503968253967% | Avg. reward: -834.5833333333334 | Avg. normalized reward: -15.455246913580247 | Avg. agents in deadlock: 16.865079365079364%| LR: 0.005


Epoch 100, testing agents on 3: Avg. done agents: 81.87003968253967% | Avg. reward: -582.2916666666666 | Avg. normalized reward: -10.783179012345679 | Avg. agents in deadlock: 13.368055555555555%| LR: 0.005


Epoch 110, testing agents on 3: Avg. done agents: 80.53075396825396% | Avg. reward: -559.4583333333334 | Avg. normalized reward: -10.36033950617284 | Avg. agents in deadlock: 7.688492063492062%| LR: 0.005


Epoch 120, testing agents on 3: Avg. done agents: 58.96825396825397% | Avg. reward: -889.375 | Avg. normalized reward: -16.46990740740741 | Avg. agents in deadlock: 10.987103174603174%| LR: 0.005


Epoch 130, testing agents on 3: Avg. done agents: 12.986111111111112% | Avg. reward: -1753.7083333333333 | Avg. normalized reward: -32.476080246913575 | Avg. agents in deadlock: 36.17063492063492%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 45.83333333333333%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 45.83333333333333%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 54.166666666666664%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 54.166666666666664%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 60.416666666666664%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 8.854166666666668% | Avg. reward: -1848.625 | Avg. normalized reward: -34.2337962962963 | Avg. agents in deadlock: 47.50496031746032%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 8.854166666666668% | Avg. reward: -1848.625 | Avg. normalized reward: -34.2337962962963 | Avg. agents in deadlock: 47.50496031746032%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 31.830357142857142%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 38.83928571428572%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 48.31349206349207%| LR: 0.005


Epoch 60, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 48.31349206349207%| LR: 0.005


Epoch 70, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 48.31349206349207%| LR: 0.005


Epoch 80, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 48.31349206349207%| LR: 0.005

