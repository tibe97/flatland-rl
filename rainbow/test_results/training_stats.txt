About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 4 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 416
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 4 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 416
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 4 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 416
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 4 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 416
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 4 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 416
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 50.124007936507944%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 50.124007936507944%| LR: 0.005

About to train 4 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 416
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 64.21626984126983% | Avg. reward: -771.1666666666666 | Avg. normalized reward: -14.280864197530864 | Avg. agents in deadlock: 14.98015873015873%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 64.21626984126983% | Avg. reward: -771.1666666666666 | Avg. normalized reward: -14.280864197530864 | Avg. agents in deadlock: 14.98015873015873%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 34.06746031746032% | Avg. reward: -1550.3333333333333 | Avg. normalized reward: -28.709876543209877 | Avg. agents in deadlock: 39.55853174603175%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 34.06746031746032% | Avg. reward: -1550.3333333333333 | Avg. normalized reward: -28.709876543209877 | Avg. agents in deadlock: 39.55853174603175%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 6.299603174603174% | Avg. reward: -1719.1666666666667 | Avg. normalized reward: -31.83641975308642 | Avg. agents in deadlock: 58.28373015873015%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 6.299603174603174% | Avg. reward: -1719.1666666666667 | Avg. normalized reward: -31.83641975308642 | Avg. agents in deadlock: 58.28373015873015%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 53.52182539682539%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 6.721230158730158% | Avg. reward: -1716.625 | Avg. normalized reward: -31.78935185185185 | Avg. agents in deadlock: 62.5%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 13.566468253968253% | Avg. reward: -1601.4583333333333 | Avg. normalized reward: -29.656635802469136 | Avg. agents in deadlock: 56.25992063492063%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 13.566468253968253% | Avg. reward: -1601.4583333333333 | Avg. normalized reward: -29.656635802469136 | Avg. agents in deadlock: 56.25992063492063%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 45.01984126984127% | Avg. reward: -1295.5 | Avg. normalized reward: -23.99074074074074 | Avg. agents in deadlock: 44.42460317460317%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 45.01984126984127% | Avg. reward: -1295.5 | Avg. normalized reward: -23.99074074074074 | Avg. agents in deadlock: 44.42460317460317%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 45.01984126984127% | Avg. reward: -1295.5 | Avg. normalized reward: -23.99074074074074 | Avg. agents in deadlock: 44.42460317460317%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 45.01984126984127% | Avg. reward: -1295.5 | Avg. normalized reward: -23.99074074074074 | Avg. agents in deadlock: 44.42460317460317%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 45.01984126984127% | Avg. reward: -1295.5 | Avg. normalized reward: -23.99074074074074 | Avg. agents in deadlock: 44.42460317460317%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 59.58829365079366% | Avg. reward: -892.125 | Avg. normalized reward: -16.520833333333332 | Avg. agents in deadlock: 14.285714285714285%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 35.45634920634921% | Avg. reward: -1395.5416666666667 | Avg. normalized reward: -25.843364197530864 | Avg. agents in deadlock: 31.433531746031747%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 35.45634920634921% | Avg. reward: -1395.5416666666667 | Avg. normalized reward: -25.843364197530864 | Avg. agents in deadlock: 31.433531746031747%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 38.50694444444444% | Avg. reward: -1347.5416666666667 | Avg. normalized reward: -24.954475308641978 | Avg. agents in deadlock: 43.973214285714285%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 38.50694444444444% | Avg. reward: -1347.5416666666667 | Avg. normalized reward: -24.954475308641978 | Avg. agents in deadlock: 43.973214285714285%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 38.50694444444444% | Avg. reward: -1347.5416666666667 | Avg. normalized reward: -24.954475308641978 | Avg. agents in deadlock: 43.973214285714285%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 30.803571428571423% | Avg. reward: -1443.5833333333333 | Avg. normalized reward: -26.733024691358022 | Avg. agents in deadlock: 56.69642857142857%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 30.803571428571423% | Avg. reward: -1443.5833333333333 | Avg. normalized reward: -26.733024691358022 | Avg. agents in deadlock: 56.69642857142857%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 6.884920634920634% | Avg. reward: -1716.875 | Avg. normalized reward: -31.79398148148148 | Avg. agents in deadlock: 62.286706349206355%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 42.604166666666664% | Avg. reward: -1153.1666666666667 | Avg. normalized reward: -21.35493827160494 | Avg. agents in deadlock: 22.32638888888889%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 42.604166666666664% | Avg. reward: -1153.1666666666667 | Avg. normalized reward: -21.35493827160494 | Avg. agents in deadlock: 22.32638888888889%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 68.82440476190474% | Avg. reward: -787.25 | Avg. normalized reward: -14.578703703703704 | Avg. agents in deadlock: 21.800595238095237%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 68.82440476190474% | Avg. reward: -787.25 | Avg. normalized reward: -14.578703703703704 | Avg. agents in deadlock: 21.800595238095237%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 68.82440476190474% | Avg. reward: -787.25 | Avg. normalized reward: -14.578703703703704 | Avg. agents in deadlock: 21.800595238095237%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 61.845238095238095% | Avg. reward: -983.125 | Avg. normalized reward: -18.20601851851852 | Avg. agents in deadlock: 25.178571428571434%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 51.230158730158735% | Avg. reward: -1233.6666666666667 | Avg. normalized reward: -22.84567901234568 | Avg. agents in deadlock: 24.642857142857142%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 51.230158730158735% | Avg. reward: -1233.6666666666667 | Avg. normalized reward: -22.84567901234568 | Avg. agents in deadlock: 24.642857142857142%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 30.625000000000007% | Avg. reward: -1328.2916666666667 | Avg. normalized reward: -24.597993827160494 | Avg. agents in deadlock: 45.53571428571428%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 30.625000000000007% | Avg. reward: -1328.2916666666667 | Avg. normalized reward: -24.597993827160494 | Avg. agents in deadlock: 45.53571428571428%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 63.07539682539682% | Avg. reward: -933.125 | Avg. normalized reward: -17.28009259259259 | Avg. agents in deadlock: 16.974206349206348%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 63.07539682539682% | Avg. reward: -933.125 | Avg. normalized reward: -17.28009259259259 | Avg. agents in deadlock: 16.974206349206348%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 63.07539682539682% | Avg. reward: -933.125 | Avg. normalized reward: -17.28009259259259 | Avg. agents in deadlock: 16.974206349206348%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 63.07539682539682% | Avg. reward: -933.125 | Avg. normalized reward: -17.28009259259259 | Avg. agents in deadlock: 16.974206349206348%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 31.52281746031746% | Avg. reward: -1343.2916666666667 | Avg. normalized reward: -24.875771604938272 | Avg. agents in deadlock: 47.99107142857142%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 31.52281746031746% | Avg. reward: -1343.2916666666667 | Avg. normalized reward: -24.875771604938272 | Avg. agents in deadlock: 47.99107142857142%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 4.4146825396825395% | Avg. reward: -1801.1666666666667 | Avg. normalized reward: -33.35493827160494 | Avg. agents in deadlock: 65.57043650793652%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 4.4146825396825395% | Avg. reward: -1801.1666666666667 | Avg. normalized reward: -33.35493827160494 | Avg. agents in deadlock: 65.57043650793652%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 5.109126984126983% | Avg. reward: -1783.0833333333333 | Avg. normalized reward: -33.02006172839506 | Avg. agents in deadlock: 55.37698412698413%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 35.9077380952381% | Avg. reward: -1209.7083333333333 | Avg. normalized reward: -22.402006172839506 | Avg. agents in deadlock: 19.285714285714285%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 35.9077380952381% | Avg. reward: -1209.7083333333333 | Avg. normalized reward: -22.402006172839506 | Avg. agents in deadlock: 19.285714285714285%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 41.99404761904762% | Avg. reward: -1186.3333333333333 | Avg. normalized reward: -21.969135802469136 | Avg. agents in deadlock: 48.333333333333336%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 41.99404761904762% | Avg. reward: -1186.3333333333333 | Avg. normalized reward: -21.969135802469136 | Avg. agents in deadlock: 48.333333333333336%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 41.99404761904762% | Avg. reward: -1186.3333333333333 | Avg. normalized reward: -21.969135802469136 | Avg. agents in deadlock: 48.333333333333336%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 41.99404761904762% | Avg. reward: -1186.3333333333333 | Avg. normalized reward: -21.969135802469136 | Avg. agents in deadlock: 48.333333333333336%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 41.99404761904762% | Avg. reward: -1186.3333333333333 | Avg. normalized reward: -21.969135802469136 | Avg. agents in deadlock: 48.333333333333336%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 43.05555555555555%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 21.30456349206349% | Avg. reward: -1398.2916666666667 | Avg. normalized reward: -25.89429012345679 | Avg. agents in deadlock: 15.892857142857144%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 46.88988095238094% | Avg. reward: -1186.7083333333333 | Avg. normalized reward: -21.97608024691358 | Avg. agents in deadlock: 32.82242063492063%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 46.88988095238094% | Avg. reward: -1186.7083333333333 | Avg. normalized reward: -21.97608024691358 | Avg. agents in deadlock: 32.82242063492063%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 60.89781746031747%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 32.19742063492064% | Avg. reward: -1274.375 | Avg. normalized reward: -23.599537037037038 | Avg. agents in deadlock: 34.74206349206349%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 13.963293650793648% | Avg. reward: -1669.2916666666667 | Avg. normalized reward: -30.91280864197531 | Avg. agents in deadlock: 48.541666666666664%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 10.803571428571429% | Avg. reward: -1817.2083333333333 | Avg. normalized reward: -33.652006172839506 | Avg. agents in deadlock: 12.5%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 32.06349206349206% | Avg. reward: -1558.0 | Avg. normalized reward: -28.85185185185185 | Avg. agents in deadlock: 19.270833333333336%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 57.16269841269842% | Avg. reward: -1022.25 | Avg. normalized reward: -18.930555555555557 | Avg. agents in deadlock: 26.235119047619044%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 83.33333333333334% | Avg. reward: -470.7916666666667 | Avg. normalized reward: -8.718364197530864 | Avg. agents in deadlock: 12.5%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 83.33333333333334% | Avg. reward: -470.7916666666667 | Avg. normalized reward: -8.718364197530864 | Avg. agents in deadlock: 12.5%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 83.33333333333334% | Avg. reward: -470.7916666666667 | Avg. normalized reward: -8.718364197530864 | Avg. agents in deadlock: 12.5%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 83.33333333333334% | Avg. reward: -470.7916666666667 | Avg. normalized reward: -8.718364197530864 | Avg. agents in deadlock: 12.5%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 82.14285714285715% | Avg. reward: -513.5416666666666 | Avg. normalized reward: -9.51003086419753 | Avg. agents in deadlock: 16.666666666666664%| LR: 0.005


Epoch 60, testing agents on 3: Avg. done agents: 84.6875% | Avg. reward: -447.25 | Avg. normalized reward: -8.282407407407407 | Avg. agents in deadlock: 6.979166666666667%| LR: 0.005


Epoch 70, testing agents on 3: Avg. done agents: 86.77083333333333% | Avg. reward: -451.5416666666667 | Avg. normalized reward: -8.361882716049383 | Avg. agents in deadlock: 6.979166666666667%| LR: 0.005


Epoch 80, testing agents on 3: Avg. done agents: 83.75% | Avg. reward: -504.375 | Avg. normalized reward: -9.340277777777779 | Avg. agents in deadlock: 11.041666666666664%| LR: 0.005


Epoch 90, testing agents on 3: Avg. done agents: 72.49503968253967% | Avg. reward: -834.5833333333334 | Avg. normalized reward: -15.455246913580247 | Avg. agents in deadlock: 16.865079365079364%| LR: 0.005


Epoch 100, testing agents on 3: Avg. done agents: 81.87003968253967% | Avg. reward: -582.2916666666666 | Avg. normalized reward: -10.783179012345679 | Avg. agents in deadlock: 13.368055555555555%| LR: 0.005


Epoch 110, testing agents on 3: Avg. done agents: 80.53075396825396% | Avg. reward: -559.4583333333334 | Avg. normalized reward: -10.36033950617284 | Avg. agents in deadlock: 7.688492063492062%| LR: 0.005


Epoch 120, testing agents on 3: Avg. done agents: 58.96825396825397% | Avg. reward: -889.375 | Avg. normalized reward: -16.46990740740741 | Avg. agents in deadlock: 10.987103174603174%| LR: 0.005


Epoch 130, testing agents on 3: Avg. done agents: 12.986111111111112% | Avg. reward: -1753.7083333333333 | Avg. normalized reward: -32.476080246913575 | Avg. agents in deadlock: 36.17063492063492%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 45.83333333333333%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 45.83333333333333%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 54.166666666666664%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 54.166666666666664%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 60.416666666666664%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 8.854166666666668% | Avg. reward: -1848.625 | Avg. normalized reward: -34.2337962962963 | Avg. agents in deadlock: 47.50496031746032%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 8.854166666666668% | Avg. reward: -1848.625 | Avg. normalized reward: -34.2337962962963 | Avg. agents in deadlock: 47.50496031746032%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 31.830357142857142%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 38.83928571428572%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 48.31349206349207%| LR: 0.005


Epoch 60, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 48.31349206349207%| LR: 0.005


Epoch 70, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 48.31349206349207%| LR: 0.005


Epoch 80, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 48.31349206349207%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 20
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 0.5208333333333333% | Avg. reward: -1883.4583333333333 | Avg. normalized reward: -34.878858024691354 | Avg. agents in deadlock: 27.142857142857142%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 17.5% | Avg. reward: -1641.5 | Avg. normalized reward: -30.39814814814815 | Avg. agents in deadlock: 48.844246031746025%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 20
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 
Epoch 10, testing agents on 3: Avg. done agents: 38.35813492063492% | Avg. reward: -1383.2916666666667 | Avg. normalized reward: -25.616512345679013 | Avg. agents in deadlock: 46.79067460317461%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 38.35813492063492% | Avg. reward: -1383.2916666666667 | Avg. normalized reward: -25.616512345679013 | Avg. agents in deadlock: 46.79067460317461%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 50
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 512
 
Epoch 10, testing agents on 3: Avg. done agents: 50.297619047619044% | Avg. reward: -1297.1666666666667 | Avg. normalized reward: -24.021604938271608 | Avg. agents in deadlock: 9.375%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 78.58134920634922% | Avg. reward: -690.9166666666666 | Avg. normalized reward: -12.794753086419753 | Avg. agents in deadlock: 12.698412698412698%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 69.72718253968253% | Avg. reward: -739.1666666666666 | Avg. normalized reward: -13.68827160493827 | Avg. agents in deadlock: 14.781746031746032%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 10
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 512
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 10
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 512
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 10
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 512
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 10
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 512
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 
Epoch 10, testing agents on 3: Avg. done agents: 81.84027777777777% | Avg. reward: -610.3333333333334 | Avg. normalized reward: -11.30246913580247 | Avg. agents in deadlock: 14.409722222222223%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 81.84027777777777% | Avg. reward: -610.3333333333334 | Avg. normalized reward: -11.30246913580247 | Avg. agents in deadlock: 14.409722222222223%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 81.84027777777777% | Avg. reward: -610.3333333333334 | Avg. normalized reward: -11.30246913580247 | Avg. agents in deadlock: 14.409722222222223%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 81.84027777777777% | Avg. reward: -610.3333333333334 | Avg. normalized reward: -11.30246913580247 | Avg. agents in deadlock: 14.409722222222223%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 84.81646825396825% | Avg. reward: -526.0416666666666 | Avg. normalized reward: -9.741512345679011 | Avg. agents in deadlock: 11.433531746031745%| LR: 0.005


Epoch 60, testing agents on 3: Avg. done agents: 81.75099206349205% | Avg. reward: -596.875 | Avg. normalized reward: -11.05324074074074 | Avg. agents in deadlock: 11.999007936507937%| LR: 0.005


Epoch 70, testing agents on 3: Avg. done agents: 83.31349206349205% | Avg. reward: -545.5 | Avg. normalized reward: -10.101851851851851 | Avg. agents in deadlock: 10.436507936507937%| LR: 0.005


Epoch 80, testing agents on 3: Avg. done agents: 76.62698412698413% | Avg. reward: -711.5 | Avg. normalized reward: -13.175925925925926 | Avg. agents in deadlock: 4.464285714285714%| LR: 0.005


Epoch 90, testing agents on 3: Avg. done agents: 72.46031746031747% | Avg. reward: -793.125 | Avg. normalized reward: -14.6875 | Avg. agents in deadlock: 7.5892857142857135%| LR: 0.005


Epoch 100, testing agents on 3: Avg. done agents: 71.86507936507937% | Avg. reward: -813.875 | Avg. normalized reward: -15.07175925925926 | Avg. agents in deadlock: 7.5892857142857135%| LR: 0.005


Epoch 110, testing agents on 3: Avg. done agents: 74.99007936507937% | Avg. reward: -758.5416666666666 | Avg. normalized reward: -14.047067901234568 | Avg. agents in deadlock: 4.464285714285714%| LR: 0.005


Epoch 120, testing agents on 3: Avg. done agents: 74.02281746031747% | Avg. reward: -756.0833333333334 | Avg. normalized reward: -14.001543209876544 | Avg. agents in deadlock: 6.547619047619048%| LR: 0.005


Epoch 130, testing agents on 3: Avg. done agents: 76.88988095238095% | Avg. reward: -658.5833333333334 | Avg. normalized reward: -12.195987654320989 | Avg. agents in deadlock: 18.943452380952383%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 128
 
Epoch 10, testing agents on 3: Avg. done agents: 10.019841269841272% | Avg. reward: -1676.1666666666667 | Avg. normalized reward: -31.040123456790123 | Avg. agents in deadlock: 46.25%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 7.415674603174603% | Avg. reward: -1696.4583333333333 | Avg. normalized reward: -31.415895061728392 | Avg. agents in deadlock: 47.8125%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 10.019841269841272% | Avg. reward: -1629.8333333333333 | Avg. normalized reward: -30.182098765432098 | Avg. agents in deadlock: 42.1875%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 20.813492063492063% | Avg. reward: -1522.375 | Avg. normalized reward: -28.19212962962963 | Avg. agents in deadlock: 43.56150793650793%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 40.29761904761904% | Avg. reward: -1326.25 | Avg. normalized reward: -24.560185185185187 | Avg. agents in deadlock: 48.83928571428572%| LR: 0.005


Epoch 60, testing agents on 3: Avg. done agents: 40.0595238095238% | Avg. reward: -1329.5833333333333 | Avg. normalized reward: -24.62191358024691 | Avg. agents in deadlock: 46.33928571428572%| LR: 0.005


Epoch 70, testing agents on 3: Avg. done agents: 40.0595238095238% | Avg. reward: -1329.5833333333333 | Avg. normalized reward: -24.62191358024691 | Avg. agents in deadlock: 46.33928571428572%| LR: 0.005


Epoch 80, testing agents on 3: Avg. done agents: 41.10119047619047% | Avg. reward: -1314.5416666666667 | Avg. normalized reward: -24.343364197530864 | Avg. agents in deadlock: 42.172619047619044%| LR: 0.005


Epoch 90, testing agents on 3: Avg. done agents: 45.267857142857146% | Avg. reward: -1299.125 | Avg. normalized reward: -24.05787037037037 | Avg. agents in deadlock: 42.172619047619044%| LR: 0.005


Epoch 100, testing agents on 3: Avg. done agents: 44.226190476190474% | Avg. reward: -1315.7083333333333 | Avg. normalized reward: -24.36496913580247 | Avg. agents in deadlock: 46.33928571428572%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 
Epoch 10, testing agents on 3: Avg. done agents: 66.73115079365078% | Avg. reward: -976.5833333333334 | Avg. normalized reward: -18.084876543209877 | Avg. agents in deadlock: 32.67361111111111%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 67.32638888888887% | Avg. reward: -961.9166666666666 | Avg. normalized reward: -17.813271604938272 | Avg. agents in deadlock: 32.67361111111111%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 68.51686507936506% | Avg. reward: -928.5416666666666 | Avg. normalized reward: -17.195216049382715 | Avg. agents in deadlock: 31.48313492063492%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 59.72222222222222%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 512
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 
Epoch 10, testing agents on 3: Avg. done agents: 19.221230158730158% | Avg. reward: -1495.9583333333333 | Avg. normalized reward: -27.70293209876543 | Avg. agents in deadlock: 47.61904761904762%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 21.30456349206349% | Avg. reward: -1474.6666666666667 | Avg. normalized reward: -27.308641975308642 | Avg. agents in deadlock: 47.61904761904762%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 20.783730158730158% | Avg. reward: -1468.5416666666667 | Avg. normalized reward: -27.19521604938272 | Avg. agents in deadlock: 47.61904761904762%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 21.65178571428571% | Avg. reward: -1446.75 | Avg. normalized reward: -26.791666666666668 | Avg. agents in deadlock: 46.230158730158735%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 20.783730158730158% | Avg. reward: -1461.0416666666667 | Avg. normalized reward: -27.05632716049383 | Avg. agents in deadlock: 47.61904761904762%| LR: 0.005


Epoch 60, testing agents on 3: Avg. done agents: 14.30059523809524% | Avg. reward: -1558.9583333333333 | Avg. normalized reward: -28.869598765432098 | Avg. agents in deadlock: 16.875%| LR: 0.005


Epoch 70, testing agents on 3: Avg. done agents: 55.17857142857142% | Avg. reward: -909.7083333333334 | Avg. normalized reward: -16.846450617283953 | Avg. agents in deadlock: 21.835317460317462%| LR: 0.005


Epoch 80, testing agents on 3: Avg. done agents: 56.403769841269835% | Avg. reward: -883.0416666666666 | Avg. normalized reward: -16.352623456790123 | Avg. agents in deadlock: 17.172619047619044%| LR: 0.005


Epoch 90, testing agents on 3: Avg. done agents: 61.820436507936506% | Avg. reward: -869.8333333333334 | Avg. normalized reward: -16.108024691358025 | Avg. agents in deadlock: 19.672619047619047%| LR: 0.005


Epoch 100, testing agents on 3: Avg. done agents: 59.1468253968254% | Avg. reward: -928.8333333333334 | Avg. normalized reward: -17.200617283950617 | Avg. agents in deadlock: 23.839285714285715%| LR: 0.005


Epoch 110, testing agents on 3: Avg. done agents: 43.621031746031754% | Avg. reward: -1113.75 | Avg. normalized reward: -20.625 | Avg. agents in deadlock: 39.21626984126984%| LR: 0.005


Epoch 120, testing agents on 3: Avg. done agents: 68.7748015873016% | Avg. reward: -720.1666666666666 | Avg. normalized reward: -13.33641975308642 | Avg. agents in deadlock: 19.866071428571427%| LR: 0.005


Epoch 130, testing agents on 3: Avg. done agents: 73.46230158730158% | Avg. reward: -692.5 | Avg. normalized reward: -12.824074074074074 | Avg. agents in deadlock: 19.345238095238095%| LR: 0.005


Epoch 140, testing agents on 3: Avg. done agents: 73.80952380952381% | Avg. reward: -695.2916666666666 | Avg. normalized reward: -12.87577160493827 | Avg. agents in deadlock: 23.511904761904763%| LR: 0.005


Epoch 150, testing agents on 3: Avg. done agents: 77.52976190476191% | Avg. reward: -670.0833333333334 | Avg. normalized reward: -12.408950617283951 | Avg. agents in deadlock: 18.75%| LR: 0.005


Epoch 160, testing agents on 3: Avg. done agents: 68.25396825396827% | Avg. reward: -736.9583333333334 | Avg. normalized reward: -13.647376543209877 | Avg. agents in deadlock: 20.38690476190476%| LR: 0.005


Epoch 170, testing agents on 3: Avg. done agents: 68.25396825396827% | Avg. reward: -737.0 | Avg. normalized reward: -13.648148148148149 | Avg. agents in deadlock: 20.38690476190476%| LR: 0.005


Epoch 180, testing agents on 3: Avg. done agents: 68.25396825396827% | Avg. reward: -736.9583333333334 | Avg. normalized reward: -13.647376543209877 | Avg. agents in deadlock: 20.38690476190476%| LR: 0.005


Epoch 190, testing agents on 3: Avg. done agents: 75.68452380952381% | Avg. reward: -674.9583333333334 | Avg. normalized reward: -12.49922839506173 | Avg. agents in deadlock: 18.511904761904763%| LR: 0.005


Epoch 200, testing agents on 3: Avg. done agents: 64.65277777777777% | Avg. reward: -928.25 | Avg. normalized reward: -17.189814814814813 | Avg. agents in deadlock: 32.66865079365079%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 78.3184523809524% | Avg. reward: -659.8333333333334 | Avg. normalized reward: -12.219135802469136 | Avg. agents in deadlock: 10.11904761904762%| LR: 0.05

Epoch 20, testing agents on 3: Avg. done agents: 78.3184523809524% | Avg. reward: -659.75 | Avg. normalized reward: -12.217592592592593 | Avg. agents in deadlock: 10.11904761904762%| LR: 0.05

Epoch 30, testing agents on 3: Avg. done agents: 78.3184523809524% | Avg. reward: -659.1666666666666 | Avg. normalized reward: -12.20679012345679 | Avg. agents in deadlock: 10.11904761904762%| LR: 0.025

Epoch 40, testing agents on 3: Avg. done agents: 78.3184523809524% | Avg. reward: -659.1666666666666 | Avg. normalized reward: -12.20679012345679 | Avg. agents in deadlock: 10.11904761904762%| LR: 0.025

Epoch 50, testing agents on 3: Avg. done agents: 75.54067460317461% | Avg. reward: -688.7916666666666 | Avg. normalized reward: -12.7554012345679 | Avg. agents in deadlock: 10.11904761904762%| LR: 0.025

Epoch 60, testing agents on 3: Avg. done agents: 63.24900793650794% | Avg. reward: -1096.75 | Avg. normalized reward: -20.310185185185187 | Avg. agents in deadlock: 20.138888888888893%| LR: 0.0125

Epoch 70, testing agents on 3: Avg. done agents: 19.791666666666664% | Avg. reward: -1838.2916666666667 | Avg. normalized reward: -34.04243827160494 | Avg. agents in deadlock: 39.88095238095238%| LR: 0.0125

Epoch 80, testing agents on 3: Avg. done agents: 8.333333333333332% | Avg. reward: -1860.5416666666667 | Avg. normalized reward: -34.454475308641975 | Avg. agents in deadlock: 31.547619047619047%| LR: 0.00625

Epoch 90, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 24.404761904761905%| LR: 0.00625

Epoch 100, testing agents on 3: Avg. done agents: 24.09722222222222% | Avg. reward: -1780.6666666666667 | Avg. normalized reward: -32.97530864197531 | Avg. agents in deadlock: 30.357142857142854%| LR: 0.00625

Epoch 110, testing agents on 3: Avg. done agents: 19.444444444444446% | Avg. reward: -1831.125 | Avg. normalized reward: -33.90972222222222 | Avg. agents in deadlock: 45.83333333333333%| LR: 0.003125

Epoch 120, testing agents on 3: Avg. done agents: 29.930555555555554% | Avg. reward: -1650.7916666666667 | Avg. normalized reward: -30.57021604938272 | Avg. agents in deadlock: 33.144841269841265%| LR: 0.003125

Epoch 130, testing agents on 3: Avg. done agents: 30.97222222222222% | Avg. reward: -1625.8333333333333 | Avg. normalized reward: -30.108024691358022 | Avg. agents in deadlock: 25.49603174603175%| LR: 0.0015625

Epoch 140, testing agents on 3: Avg. done agents: 30.97222222222222% | Avg. reward: -1628.75 | Avg. normalized reward: -30.162037037037038 | Avg. agents in deadlock: 24.662698412698415%| LR: 0.0015625

Epoch 150, testing agents on 3: Avg. done agents: 27.708333333333336% | Avg. reward: -1695.1666666666667 | Avg. normalized reward: -31.391975308641978 | Avg. agents in deadlock: 23.21428571428571%| LR: 0.0015625

Epoch 160, testing agents on 3: Avg. done agents: 28.40277777777778% | Avg. reward: -1694.625 | Avg. normalized reward: -31.381944444444443 | Avg. agents in deadlock: 29.672619047619047%| LR: 0.00078125
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 11.11111111111111% | Avg. reward: -1746.9583333333333 | Avg. normalized reward: -32.351080246913575 | Avg. agents in deadlock: 50.81845238095239%| LR: 0.05

Epoch 20, testing agents on 3: Avg. done agents: 11.11111111111111% | Avg. reward: -1745.625 | Avg. normalized reward: -32.326388888888886 | Avg. agents in deadlock: 50.81845238095239%| LR: 0.05

Epoch 30, testing agents on 3: Avg. done agents: 11.11111111111111% | Avg. reward: -1745.625 | Avg. normalized reward: -32.326388888888886 | Avg. agents in deadlock: 50.81845238095239%| LR: 0.025

Epoch 40, testing agents on 3: Avg. done agents: 11.11111111111111% | Avg. reward: -1745.625 | Avg. normalized reward: -32.326388888888886 | Avg. agents in deadlock: 50.81845238095239%| LR: 0.025

Epoch 50, testing agents on 3: Avg. done agents: 11.11111111111111% | Avg. reward: -1746.9583333333333 | Avg. normalized reward: -32.351080246913575 | Avg. agents in deadlock: 50.81845238095239%| LR: 0.025

Epoch 60, testing agents on 3: Avg. done agents: 11.11111111111111% | Avg. reward: -1745.625 | Avg. normalized reward: -32.326388888888886 | Avg. agents in deadlock: 50.81845238095239%| LR: 0.0125

Epoch 70, testing agents on 3: Avg. done agents: 11.11111111111111% | Avg. reward: -1745.625 | Avg. normalized reward: -32.326388888888886 | Avg. agents in deadlock: 50.81845238095239%| LR: 0.0125

Epoch 80, testing agents on 3: Avg. done agents: 11.11111111111111% | Avg. reward: -1745.625 | Avg. normalized reward: -32.326388888888886 | Avg. agents in deadlock: 50.81845238095239%| LR: 0.00625

Epoch 90, testing agents on 3: Avg. done agents: 3.125% | Avg. reward: -1856.5 | Avg. normalized reward: -34.379629629629626 | Avg. agents in deadlock: 54.91071428571429%| LR: 0.00625

Epoch 100, testing agents on 3: Avg. done agents: 3.125% | Avg. reward: -1855.1666666666667 | Avg. normalized reward: -34.35493827160494 | Avg. agents in deadlock: 54.91071428571429%| LR: 0.00625

Epoch 110, testing agents on 3: Avg. done agents: 3.125% | Avg. reward: -1856.5 | Avg. normalized reward: -34.379629629629626 | Avg. agents in deadlock: 54.91071428571429%| LR: 0.003125

Epoch 120, testing agents on 3: Avg. done agents: 1.0416666666666665% | Avg. reward: -1886.5416666666667 | Avg. normalized reward: -34.935956790123456 | Avg. agents in deadlock: 54.91071428571429%| LR: 0.003125

Epoch 130, testing agents on 3: Avg. done agents: 1.0416666666666665% | Avg. reward: -1886.5416666666667 | Avg. normalized reward: -34.935956790123456 | Avg. agents in deadlock: 55.952380952380956%| LR: 0.0015625

Epoch 140, testing agents on 3: Avg. done agents: 1.0416666666666665% | Avg. reward: -1886.5416666666667 | Avg. normalized reward: -34.935956790123456 | Avg. agents in deadlock: 55.952380952380956%| LR: 0.0015625
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.99
learning_rate: 0.02
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -10
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.99
learning_rate: 0.02
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -10
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.99
learning_rate: 0.02
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -10
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.99
learning_rate: 0.02
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -10
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.99
learning_rate: 0.02
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -10
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.99
learning_rate: 0.02
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -10
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.99
learning_rate: 0.02
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -10
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 59.350198412698404% | Avg. reward: -968.1666666666666 | Avg. normalized reward: -17.929012345679013 | Avg. agents in deadlock: 14.112103174603174%| LR: 0.007199999999999998

Epoch 20, testing agents on 3: Avg. done agents: 58.754960317460316% | Avg. reward: -979.875 | Avg. normalized reward: -18.145833333333332 | Avg. agents in deadlock: 13.070436507936508%| LR: 0.015199999999999997

Epoch 30, testing agents on 3: Avg. done agents: 56.374007936507944% | Avg. reward: -1049.7916666666667 | Avg. normalized reward: -19.44058641975309 | Avg. agents in deadlock: 16.493055555555554%| LR: 0.0168

Epoch 40, testing agents on 3: Avg. done agents: 53.79960317460317% | Avg. reward: -1168.5833333333333 | Avg. normalized reward: -21.64043209876543 | Avg. agents in deadlock: 24.598214285714285%| LR: 0.008799999999999999

Epoch 50, testing agents on 3: Avg. done agents: 55.610119047619044% | Avg. reward: -1119.4583333333333 | Avg. normalized reward: -20.73070987654321 | Avg. agents in deadlock: 22.78769841269841%| LR: 0.0008000000000000007

Epoch 60, testing agents on 3: Avg. done agents: 50.74900793650793% | Avg. reward: -1178.7083333333333 | Avg. normalized reward: -21.82793209876543 | Avg. agents in deadlock: 27.648809523809526%| LR: 0.0035999999999999943

Epoch 70, testing agents on 3: Avg. done agents: 53.03075396825396% | Avg. reward: -1155.0416666666667 | Avg. normalized reward: -21.38966049382716 | Avg. agents in deadlock: 25.21825396825397%| LR: 0.007599999999999998

Epoch 80, testing agents on 3: Avg. done agents: 45.59027777777777% | Avg. reward: -1263.2916666666667 | Avg. normalized reward: -23.39429012345679 | Avg. agents in deadlock: 31.46825396825397%| LR: 0.0084

Epoch 90, testing agents on 3: Avg. done agents: 50.45138888888889% | Avg. reward: -1195.9166666666667 | Avg. normalized reward: -22.146604938271608 | Avg. agents in deadlock: 25.71428571428572%| LR: 0.004399999999999995

Epoch 100, testing agents on 3: Avg. done agents: 50.89781746031746% | Avg. reward: -1195.0416666666667 | Avg. normalized reward: -22.130401234567902 | Avg. agents in deadlock: 29.087301587301585%| LR: 0.00040000000000000034

Epoch 110, testing agents on 3: Avg. done agents: 52.68353174603174% | Avg. reward: -1158.8333333333333 | Avg. normalized reward: -21.459876543209877 | Avg. agents in deadlock: 26.30952380952381%| LR: 0.0018000000000000017

Epoch 120, testing agents on 3: Avg. done agents: 48.12003968253968% | Avg. reward: -1231.0416666666667 | Avg. normalized reward: -22.79706790123457 | Avg. agents in deadlock: 29.087301587301585%| LR: 0.003799999999999999

Epoch 130, testing agents on 3: Avg. done agents: 50.89781746031746% | Avg. reward: -1195.125 | Avg. normalized reward: -22.131944444444443 | Avg. agents in deadlock: 26.30952380952381%| LR: 0.0042

Epoch 140, testing agents on 3: Avg. done agents: 50.89781746031746% | Avg. reward: -1195.0 | Avg. normalized reward: -22.12962962962963 | Avg. agents in deadlock: 26.30952380952381%| LR: 0.002200000000000002

Epoch 150, testing agents on 3: Avg. done agents: 47.6736111111111% | Avg. reward: -1241.9583333333333 | Avg. normalized reward: -22.999228395061728 | Avg. agents in deadlock: 29.087301587301585%| LR: 0.00020000000000000017

Epoch 160, testing agents on 3: Avg. done agents: 48.4672619047619% | Avg. reward: -1236.125 | Avg. normalized reward: -22.891203703703702 | Avg. agents in deadlock: 25.11904761904762%| LR: 0.0008999999999999986

Epoch 170, testing agents on 3: Avg. done agents: 49.905753968253954% | Avg. reward: -1185.125 | Avg. normalized reward: -21.94675925925926 | Avg. agents in deadlock: 29.087301587301585%| LR: 0.0018999999999999996

Epoch 180, testing agents on 3: Avg. done agents: 47.425595238095234% | Avg. reward: -1251.5416666666667 | Avg. normalized reward: -23.1766975308642 | Avg. agents in deadlock: 28.59126984126984%| LR: 0.0021

Epoch 190, testing agents on 3: Avg. done agents: 47.6736111111111% | Avg. reward: -1241.9583333333333 | Avg. normalized reward: -22.999228395061728 | Avg. agents in deadlock: 27.896825396825392%| LR: 0.0011000000000000033

Epoch 200, testing agents on 3: Avg. done agents: 49.50892857142857% | Avg. reward: -1211.7916666666667 | Avg. normalized reward: -22.44058641975309 | Avg. agents in deadlock: 25.11904761904762%| LR: 9.999999999999788e-05
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.99
learning_rate: 0.02
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 48.149801587301575% | Avg. reward: -1398.625 | Avg. normalized reward: -25.900462962962962 | Avg. agents in deadlock: 43.4375%| LR: 0.007199999999999998

Epoch 20, testing agents on 3: Avg. done agents: 46.3640873015873% | Avg. reward: -1443.375 | Avg. normalized reward: -26.729166666666668 | Avg. agents in deadlock: 42.24702380952381%| LR: 0.015199999999999997

Epoch 30, testing agents on 3: Avg. done agents: 47.6736111111111% | Avg. reward: -1391.625 | Avg. normalized reward: -25.770833333333332 | Avg. agents in deadlock: 45.58035714285714%| LR: 0.0168

Epoch 40, testing agents on 3: Avg. done agents: 45.694444444444436% | Avg. reward: -1438.4166666666667 | Avg. normalized reward: -26.63734567901235 | Avg. agents in deadlock: 46.31448412698413%| LR: 0.008799999999999999

Epoch 50, testing agents on 3: Avg. done agents: 46.42857142857142% | Avg. reward: -1421.625 | Avg. normalized reward: -26.32638888888889 | Avg. agents in deadlock: 45.40674603174602%| LR: 0.0008000000000000007

Epoch 60, testing agents on 3: Avg. done agents: 46.42857142857142% | Avg. reward: -1419.2083333333333 | Avg. normalized reward: -26.281635802469136 | Avg. agents in deadlock: 45.40674603174602%| LR: 0.0035999999999999943

Epoch 70, testing agents on 3: Avg. done agents: 48.07539682539683% | Avg. reward: -1315.6666666666667 | Avg. normalized reward: -24.3641975308642 | Avg. agents in deadlock: 42.648809523809526%| LR: 0.007599999999999998

Epoch 80, testing agents on 3: Avg. done agents: 51.80555555555556% | Avg. reward: -1282.75 | Avg. normalized reward: -23.75462962962963 | Avg. agents in deadlock: 33.482142857142854%| LR: 0.0084

Epoch 90, testing agents on 3: Avg. done agents: 51.80555555555556% | Avg. reward: -1282.9166666666667 | Avg. normalized reward: -23.75771604938272 | Avg. agents in deadlock: 33.482142857142854%| LR: 0.004399999999999995

Epoch 100, testing agents on 3: Avg. done agents: 51.80555555555556% | Avg. reward: -1282.6666666666667 | Avg. normalized reward: -23.75308641975309 | Avg. agents in deadlock: 33.482142857142854%| LR: 0.00040000000000000034

Epoch 110, testing agents on 3: Avg. done agents: 51.80555555555556% | Avg. reward: -1284.3333333333333 | Avg. normalized reward: -23.78395061728395 | Avg. agents in deadlock: 33.482142857142854%| LR: 0.0018000000000000017

Epoch 120, testing agents on 3: Avg. done agents: 51.80555555555556% | Avg. reward: -1282.75 | Avg. normalized reward: -23.75462962962963 | Avg. agents in deadlock: 33.482142857142854%| LR: 0.003799999999999999

Epoch 130, testing agents on 3: Avg. done agents: 50.01984126984127% | Avg. reward: -1330.5 | Avg. normalized reward: -24.63888888888889 | Avg. agents in deadlock: 35.86309523809524%| LR: 0.0042

Epoch 140, testing agents on 3: Avg. done agents: 50.01984126984127% | Avg. reward: -1330.5 | Avg. normalized reward: -24.63888888888889 | Avg. agents in deadlock: 35.86309523809524%| LR: 0.002200000000000002

Epoch 150, testing agents on 3: Avg. done agents: 50.01984126984127% | Avg. reward: -1330.6666666666667 | Avg. normalized reward: -24.641975308641978 | Avg. agents in deadlock: 35.86309523809524%| LR: 0.00020000000000000017

Epoch 160, testing agents on 3: Avg. done agents: 50.01984126984127% | Avg. reward: -1330.6666666666667 | Avg. normalized reward: -24.641975308641978 | Avg. agents in deadlock: 35.86309523809524%| LR: 0.0008999999999999986

Epoch 170, testing agents on 3: Avg. done agents: 50.01984126984127% | Avg. reward: -1330.5833333333333 | Avg. normalized reward: -24.64043209876543 | Avg. agents in deadlock: 35.86309523809524%| LR: 0.0018999999999999996

Epoch 180, testing agents on 3: Avg. done agents: 48.829365079365076% | Avg. reward: -1365.0 | Avg. normalized reward: -25.27777777777778 | Avg. agents in deadlock: 37.05357142857142%| LR: 0.0021

Epoch 190, testing agents on 3: Avg. done agents: 50.01984126984127% | Avg. reward: -1330.5833333333333 | Avg. normalized reward: -24.64043209876543 | Avg. agents in deadlock: 35.86309523809524%| LR: 0.0011000000000000033

Epoch 200, testing agents on 3: Avg. done agents: 50.01984126984127% | Avg. reward: -1330.5 | Avg. normalized reward: -24.63888888888889 | Avg. agents in deadlock: 35.86309523809524%| LR: 9.999999999999788e-05
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.99
learning_rate: 0.01
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 60.71428571428571%| LR: 0.003599999999999999

Epoch 20, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 60.71428571428571%| LR: 0.007599999999999998

Epoch 30, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 21.428571428571427%| LR: 0.0084

Epoch 40, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 27.281746031746028%| LR: 0.004399999999999999

Epoch 50, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 23.80952380952381%| LR: 0.00040000000000000034

Epoch 60, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 23.80952380952381%| LR: 0.0017999999999999971

Epoch 70, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 23.80952380952381%| LR: 0.003799999999999999

Epoch 80, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 27.976190476190478%| LR: 0.0042

Epoch 90, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 48.80952380952381%| LR: 0.0021999999999999975

Epoch 100, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 48.80952380952381%| LR: 0.00020000000000000017

Epoch 110, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 48.80952380952381%| LR: 0.0009000000000000008

Epoch 120, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 48.80952380952381%| LR: 0.0018999999999999996

Epoch 130, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 48.80952380952381%| LR: 0.0021

Epoch 140, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 46.42857142857142%| LR: 0.001100000000000001

Epoch 150, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 46.42857142857142%| LR: 0.00010000000000000009

Epoch 160, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 46.42857142857142%| LR: 0.0004499999999999993

Epoch 170, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 48.80952380952381%| LR: 0.0009499999999999998

Epoch 180, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 61.3095238095238%| LR: 0.00105

Epoch 190, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 48.80952380952381%| LR: 0.0005500000000000017

Epoch 200, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 48.80952380952381%| LR: 4.999999999999894e-05
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.99
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.99
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 23.75% | Avg. reward: -1757.1666666666667 | Avg. normalized reward: -32.54012345679013 | Avg. agents in deadlock: 68.95833333333333%| LR: 0.010799999999999995

Epoch 20, testing agents on 3: Avg. done agents: 44.6031746031746% | Avg. reward: -1432.625 | Avg. normalized reward: -26.53009259259259 | Avg. agents in deadlock: 45.32738095238095%| LR: 0.022799999999999994

Epoch 30, testing agents on 3: Avg. done agents: 8.973214285714286% | Avg. reward: -1720.1666666666667 | Avg. normalized reward: -31.85493827160494 | Avg. agents in deadlock: 47.3313492063492%| LR: 0.025199999999999993

Epoch 40, testing agents on 3: Avg. done agents: 49.737103174603156% | Avg. reward: -1336.3333333333333 | Avg. normalized reward: -24.74691358024691 | Avg. agents in deadlock: 44.0625%| LR: 0.013199999999999998

Epoch 50, testing agents on 3: Avg. done agents: 50.332341269841265% | Avg. reward: -1319.2916666666667 | Avg. normalized reward: -24.43132716049383 | Avg. agents in deadlock: 43.467261904761905%| LR: 0.001200000000000001

Epoch 60, testing agents on 3: Avg. done agents: 49.737103174603156% | Avg. reward: -1339.0 | Avg. normalized reward: -24.796296296296298 | Avg. agents in deadlock: 44.0625%| LR: 0.005399999999999992

Epoch 70, testing agents on 3: Avg. done agents: 48.48710317460316% | Avg. reward: -1359.2083333333333 | Avg. normalized reward: -25.170524691358022 | Avg. agents in deadlock: 44.479166666666664%| LR: 0.011399999999999997

Epoch 80, testing agents on 3: Avg. done agents: 47.44543650793649% | Avg. reward: -1366.2083333333333 | Avg. normalized reward: -25.30015432098765 | Avg. agents in deadlock: 42.04861111111111%| LR: 0.012599999999999997

Epoch 90, testing agents on 3: Avg. done agents: 51.40376984126983% | Avg. reward: -1314.5833333333333 | Avg. normalized reward: -24.344135802469136 | Avg. agents in deadlock: 41.006944444444436%| LR: 0.006599999999999992

Epoch 100, testing agents on 3: Avg. done agents: 53.487103174603156% | Avg. reward: -1282.1666666666667 | Avg. normalized reward: -23.74382716049383 | Avg. agents in deadlock: 38.92361111111111%| LR: 0.0006000000000000005

Epoch 110, testing agents on 3: Avg. done agents: 51.26488095238094% | Avg. reward: -1310.25 | Avg. normalized reward: -24.26388888888889 | Avg. agents in deadlock: 41.701388888888886%| LR: 0.0027000000000000023

Epoch 120, testing agents on 3: Avg. done agents: 52.09821428571427% | Avg. reward: -1292.9166666666667 | Avg. normalized reward: -23.942901234567902 | Avg. agents in deadlock: 41.701388888888886%| LR: 0.0056999999999999985

Epoch 130, testing agents on 3: Avg. done agents: 52.693452380952365% | Avg. reward: -1278.5416666666667 | Avg. normalized reward: -23.6766975308642 | Avg. agents in deadlock: 41.10615079365079%| LR: 0.006299999999999998

Epoch 140, testing agents on 3: Avg. done agents: 52.693452380952365% | Avg. reward: -1278.5416666666667 | Avg. normalized reward: -23.6766975308642 | Avg. agents in deadlock: 41.10615079365079%| LR: 0.003300000000000003

Epoch 150, testing agents on 3: Avg. done agents: 51.99900793650792% | Avg. reward: -1297.4583333333333 | Avg. normalized reward: -24.027006172839506 | Avg. agents in deadlock: 40.41170634920634%| LR: 0.00030000000000000024

Epoch 160, testing agents on 3: Avg. done agents: 52.09821428571427% | Avg. reward: -1295.5833333333333 | Avg. normalized reward: -23.99228395061728 | Avg. agents in deadlock: 41.701388888888886%| LR: 0.001349999999999998

Epoch 170, testing agents on 3: Avg. done agents: 52.693452380952365% | Avg. reward: -1278.5416666666667 | Avg. normalized reward: -23.6766975308642 | Avg. agents in deadlock: 41.10615079365079%| LR: 0.0028499999999999992

Epoch 180, testing agents on 3: Avg. done agents: 52.693452380952365% | Avg. reward: -1278.5416666666667 | Avg. normalized reward: -23.6766975308642 | Avg. agents in deadlock: 41.10615079365079%| LR: 0.003149999999999999

Epoch 190, testing agents on 3: Avg. done agents: 52.693452380952365% | Avg. reward: -1278.5416666666667 | Avg. normalized reward: -23.6766975308642 | Avg. agents in deadlock: 41.10615079365079%| LR: 0.0016500000000000048

Epoch 200, testing agents on 3: Avg. done agents: 52.693452380952365% | Avg. reward: -1278.5416666666667 | Avg. normalized reward: -23.6766975308642 | Avg. agents in deadlock: 41.10615079365079%| LR: 0.0001499999999999968
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 35.28769841269842% | Avg. reward: -1517.75 | Avg. normalized reward: -28.10648148148148 | Avg. agents in deadlock: 24.692460317460316%| LR: 0.010799999999999995

Epoch 20, testing agents on 3: Avg. done agents: 36.31944444444444% | Avg. reward: -1504.8333333333333 | Avg. normalized reward: -27.86728395061728 | Avg. agents in deadlock: 24.692460317460316%| LR: 0.022799999999999994

Epoch 30, testing agents on 3: Avg. done agents: 36.0218253968254% | Avg. reward: -1479.9166666666667 | Avg. normalized reward: -27.405864197530864 | Avg. agents in deadlock: 21.121031746031747%| LR: 0.025199999999999993

Epoch 40, testing agents on 3: Avg. done agents: 26.89484126984127% | Avg. reward: -1523.9166666666667 | Avg. normalized reward: -28.22067901234568 | Avg. agents in deadlock: 23.74007936507936%| LR: 0.013199999999999998

Epoch 50, testing agents on 3: Avg. done agents: 36.62698412698413% | Avg. reward: -1444.4583333333333 | Avg. normalized reward: -26.749228395061728 | Avg. agents in deadlock: 30.08928571428571%| LR: 0.001200000000000001

Epoch 60, testing agents on 3: Avg. done agents: 47.93154761904761% | Avg. reward: -1258.0 | Avg. normalized reward: -23.296296296296298 | Avg. agents in deadlock: 27.981150793650794%| LR: 0.005399999999999992

Epoch 70, testing agents on 3: Avg. done agents: 50.18353174603174% | Avg. reward: -1322.4583333333333 | Avg. normalized reward: -24.48996913580247 | Avg. agents in deadlock: 30.600198412698415%| LR: 0.011399999999999997

Epoch 80, testing agents on 3: Avg. done agents: 27.99603174603175% | Avg. reward: -1612.0 | Avg. normalized reward: -29.85185185185185 | Avg. agents in deadlock: 26.939484126984127%| LR: 0.012599999999999997

Epoch 90, testing agents on 3: Avg. done agents: 10.416666666666668% | Avg. reward: -1837.4166666666667 | Avg. normalized reward: -34.026234567901234 | Avg. agents in deadlock: 57.73809523809524%| LR: 0.006599999999999992
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 11.398809523809524% | Avg. reward: -1766.875 | Avg. normalized reward: -32.719907407407405 | Avg. agents in deadlock: 63.601190476190474%| LR: 0.010799999999999995

Epoch 20, testing agents on 3: Avg. done agents: 11.498015873015872% | Avg. reward: -1752.9583333333333 | Avg. normalized reward: -32.46219135802469 | Avg. agents in deadlock: 56.25992063492063%| LR: 0.022799999999999994
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 25.28769841269841% | Avg. reward: -1730.4583333333333 | Avg. normalized reward: -32.045524691358025 | Avg. agents in deadlock: 52.083333333333336%| LR: 0.010799999999999995

Epoch 20, testing agents on 3: Avg. done agents: 24.69246031746032% | Avg. reward: -1722.3333333333333 | Avg. normalized reward: -31.89506172839506 | Avg. agents in deadlock: 56.25%| LR: 0.022799999999999994

Epoch 30, testing agents on 3: Avg. done agents: 24.69246031746032% | Avg. reward: -1737.3333333333333 | Avg. normalized reward: -32.172839506172835 | Avg. agents in deadlock: 61.904761904761905%| LR: 0.025199999999999993

Epoch 40, testing agents on 3: Avg. done agents: 29.136904761904763% | Avg. reward: -1660.6666666666667 | Avg. normalized reward: -30.75308641975309 | Avg. agents in deadlock: 47.91666666666667%| LR: 0.013199999999999998

Epoch 50, testing agents on 3: Avg. done agents: 29.136904761904763% | Avg. reward: -1673.9166666666667 | Avg. normalized reward: -30.99845679012346 | Avg. agents in deadlock: 45.83333333333333%| LR: 0.001200000000000001

Epoch 60, testing agents on 3: Avg. done agents: 29.136904761904763% | Avg. reward: -1673.4166666666667 | Avg. normalized reward: -30.9891975308642 | Avg. agents in deadlock: 50.89285714285714%| LR: 0.005399999999999992

Epoch 70, testing agents on 3: Avg. done agents: 29.732142857142858% | Avg. reward: -1664.2916666666667 | Avg. normalized reward: -30.82021604938272 | Avg. agents in deadlock: 46.35416666666667%| LR: 0.011399999999999997

Epoch 80, testing agents on 3: Avg. done agents: 29.136904761904763% | Avg. reward: -1660.5833333333333 | Avg. normalized reward: -30.75154320987654 | Avg. agents in deadlock: 41.66666666666667%| LR: 0.012599999999999997

Epoch 90, testing agents on 3: Avg. done agents: 29.136904761904763% | Avg. reward: -1689.5833333333333 | Avg. normalized reward: -31.28858024691358 | Avg. agents in deadlock: 49.70238095238095%| LR: 0.006599999999999992

Epoch 100, testing agents on 3: Avg. done agents: 29.136904761904763% | Avg. reward: -1667.8333333333333 | Avg. normalized reward: -30.8858024691358 | Avg. agents in deadlock: 46.57738095238095%| LR: 0.0006000000000000005

Epoch 110, testing agents on 3: Avg. done agents: 29.136904761904763% | Avg. reward: -1679.9166666666667 | Avg. normalized reward: -31.10956790123457 | Avg. agents in deadlock: 39.93055555555555%| LR: 0.0027000000000000023

Epoch 120, testing agents on 3: Avg. done agents: 39.360119047619044% | Avg. reward: -1506.2916666666667 | Avg. normalized reward: -27.89429012345679 | Avg. agents in deadlock: 41.889880952380956%| LR: 0.0056999999999999985

Epoch 130, testing agents on 3: Avg. done agents: 37.648809523809526% | Avg. reward: -1553.7083333333333 | Avg. normalized reward: -28.772376543209877 | Avg. agents in deadlock: 37.847222222222214%| LR: 0.006299999999999998

Epoch 140, testing agents on 3: Avg. done agents: 37.05357142857142% | Avg. reward: -1605.4166666666667 | Avg. normalized reward: -29.72993827160494 | Avg. agents in deadlock: 42.41071428571428%| LR: 0.003300000000000003

Epoch 150, testing agents on 3: Avg. done agents: 36.01190476190476% | Avg. reward: -1606.0833333333333 | Avg. normalized reward: -29.74228395061728 | Avg. agents in deadlock: 39.28571428571428%| LR: 0.00030000000000000024

Epoch 160, testing agents on 3: Avg. done agents: 32.88690476190476% | Avg. reward: -1608.75 | Avg. normalized reward: -29.791666666666668 | Avg. agents in deadlock: 43.45238095238095%| LR: 0.001349999999999998

Epoch 170, testing agents on 3: Avg. done agents: 30.80357142857143% | Avg. reward: -1647.7916666666667 | Avg. normalized reward: -30.51466049382716 | Avg. agents in deadlock: 46.57738095238095%| LR: 0.0028499999999999992

Epoch 180, testing agents on 3: Avg. done agents: 29.136904761904763% | Avg. reward: -1674.3333333333333 | Avg. normalized reward: -31.00617283950617 | Avg. agents in deadlock: 43.45238095238095%| LR: 0.003149999999999999

Epoch 190, testing agents on 3: Avg. done agents: 33.0952380952381% | Avg. reward: -1622.4166666666667 | Avg. normalized reward: -30.044753086419753 | Avg. agents in deadlock: 43.45238095238095%| LR: 0.0016500000000000048
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -100
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 35.391865079365076% | Avg. reward: -1233.3333333333333 | Avg. normalized reward: -22.839506172839506 | Avg. agents in deadlock: 18.62599206349206%| LR: 0.010799999999999995

Epoch 20, testing agents on 3: Avg. done agents: 32.3313492063492% | Avg. reward: -1314.125 | Avg. normalized reward: -24.33564814814815 | Avg. agents in deadlock: 20.585317460317455%| LR: 0.022799999999999994

Epoch 30, testing agents on 3: Avg. done agents: 34.34027777777778% | Avg. reward: -1279.375 | Avg. normalized reward: -23.69212962962963 | Avg. agents in deadlock: 21.82043650793651%| LR: 0.025199999999999993

Epoch 40, testing agents on 3: Avg. done agents: 23.273809523809522% | Avg. reward: -1568.0416666666667 | Avg. normalized reward: -29.03780864197531 | Avg. agents in deadlock: 42.32142857142857%| LR: 0.013199999999999998

Epoch 50, testing agents on 3: Avg. done agents: 24.166666666666668% | Avg. reward: -1492.7916666666667 | Avg. normalized reward: -27.64429012345679 | Avg. agents in deadlock: 34.583333333333336%| LR: 0.001200000000000001

Epoch 60, testing agents on 3: Avg. done agents: 22.976190476190474% | Avg. reward: -1525.6666666666667 | Avg. normalized reward: -28.25308641975309 | Avg. agents in deadlock: 39.345238095238095%| LR: 0.005399999999999992

Epoch 70, testing agents on 3: Avg. done agents: 20.5952380952381% | Avg. reward: -1589.5833333333333 | Avg. normalized reward: -29.436728395061728 | Avg. agents in deadlock: 41.72619047619047%| LR: 0.011399999999999997

Epoch 80, testing agents on 3: Avg. done agents: 28.184523809523803% | Avg. reward: -1518.625 | Avg. normalized reward: -28.122685185185187 | Avg. agents in deadlock: 43.51190476190476%| LR: 0.012599999999999997

Epoch 90, testing agents on 3: Avg. done agents: 23.124999999999996% | Avg. reward: -1634.1666666666667 | Avg. normalized reward: -30.26234567901235 | Avg. agents in deadlock: 39.94047619047619%| LR: 0.006599999999999992

Epoch 100, testing agents on 3: Avg. done agents: 23.72023809523809% | Avg. reward: -1592.2083333333333 | Avg. normalized reward: -29.48533950617284 | Avg. agents in deadlock: 38.30357142857143%| LR: 0.0006000000000000005

Epoch 110, testing agents on 3: Avg. done agents: 22.88690476190476% | Avg. reward: -1623.5416666666667 | Avg. normalized reward: -30.06558641975309 | Avg. agents in deadlock: 39.345238095238095%| LR: 0.0027000000000000023

Epoch 120, testing agents on 3: Avg. done agents: 30.853174603174597% | Avg. reward: -1492.7083333333333 | Avg. normalized reward: -27.642746913580247 | Avg. agents in deadlock: 38.601190476190474%| LR: 0.0056999999999999985

Epoch 130, testing agents on 3: Avg. done agents: 26.636904761904763% | Avg. reward: -1467.5833333333333 | Avg. normalized reward: -27.17746913580247 | Avg. agents in deadlock: 38.75%| LR: 0.006299999999999998

Epoch 140, testing agents on 3: Avg. done agents: 32.0436507936508% | Avg. reward: -1454.9166666666667 | Avg. normalized reward: -26.942901234567902 | Avg. agents in deadlock: 35.773809523809526%| LR: 0.003300000000000003

Epoch 150, testing agents on 3: Avg. done agents: 32.0436507936508% | Avg. reward: -1446.1666666666667 | Avg. normalized reward: -26.780864197530864 | Avg. agents in deadlock: 35.773809523809526%| LR: 0.00030000000000000024

Epoch 160, testing agents on 3: Avg. done agents: 30.406746031746028% | Avg. reward: -1476.5416666666667 | Avg. normalized reward: -27.343364197530864 | Avg. agents in deadlock: 39.345238095238095%| LR: 0.001349999999999998

Epoch 170, testing agents on 3: Avg. done agents: 32.0436507936508% | Avg. reward: -1444.5 | Avg. normalized reward: -26.75 | Avg. agents in deadlock: 35.773809523809526%| LR: 0.0028499999999999992

Epoch 180, testing agents on 3: Avg. done agents: 28.025793650793652% | Avg. reward: -1541.9583333333333 | Avg. normalized reward: -28.55478395061728 | Avg. agents in deadlock: 39.345238095238095%| LR: 0.003149999999999999

Epoch 190, testing agents on 3: Avg. done agents: 30.406746031746028% | Avg. reward: -1476.5416666666667 | Avg. normalized reward: -27.343364197530864 | Avg. agents in deadlock: 39.345238095238095%| LR: 0.0016500000000000048

Epoch 200, testing agents on 3: Avg. done agents: 28.025793650793652% | Avg. reward: -1542.7916666666667 | Avg. normalized reward: -28.57021604938272 | Avg. agents in deadlock: 39.345238095238095%| LR: 0.0001499999999999968
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.992
learning_rate: 0.03
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 6.746031746031746% | Avg. reward: -1785.7083333333333 | Avg. normalized reward: -33.06867283950617 | Avg. agents in deadlock: 43.998015873015866%| LR: 0.010799999999999995

Epoch 20, testing agents on 3: Avg. done agents: 7.638888888888888% | Avg. reward: -1787.4583333333333 | Avg. normalized reward: -33.101080246913575 | Avg. agents in deadlock: 47.79761904761905%| LR: 0.022799999999999994

Epoch 30, testing agents on 3: Avg. done agents: 10.734126984126984% | Avg. reward: -1723.9583333333333 | Avg. normalized reward: -31.92515432098765 | Avg. agents in deadlock: 39.28571428571428%| LR: 0.025199999999999993

Epoch 40, testing agents on 3: Avg. done agents: 12.5% | Avg. reward: -1824.0416666666667 | Avg. normalized reward: -33.77854938271605 | Avg. agents in deadlock: 69.79166666666666%| LR: 0.013199999999999998

Epoch 50, testing agents on 3: Avg. done agents: 13.88888888888889% | Avg. reward: -1818.6666666666667 | Avg. normalized reward: -33.67901234567901 | Avg. agents in deadlock: 68.40277777777777%| LR: 0.001200000000000001

Epoch 60, testing agents on 3: Avg. done agents: 21.875% | Avg. reward: -1777.7083333333333 | Avg. normalized reward: -32.920524691358025 | Avg. agents in deadlock: 65.27777777777779%| LR: 0.005399999999999992

Epoch 70, testing agents on 3: Avg. done agents: 33.5515873015873% | Avg. reward: -1612.9166666666667 | Avg. normalized reward: -29.86882716049383 | Avg. agents in deadlock: 56.329365079365076%| LR: 0.011399999999999997

Epoch 80, testing agents on 3: Avg. done agents: 33.47222222222222% | Avg. reward: -1627.9583333333333 | Avg. normalized reward: -30.147376543209877 | Avg. agents in deadlock: 55.813492063492056%| LR: 0.012599999999999997

Epoch 90, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 61.11111111111111%| LR: 0.006599999999999992

Epoch 100, testing agents on 3: Avg. done agents: 1.0416666666666665% | Avg. reward: -1882.0416666666667 | Avg. normalized reward: -34.85262345679013 | Avg. agents in deadlock: 55.00992063492064%| LR: 0.0006000000000000005

Epoch 110, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 64.75694444444444%| LR: 0.0027000000000000023

Epoch 120, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 55.43154761904761%| LR: 0.0056999999999999985

Epoch 130, testing agents on 3: Avg. done agents: 8.040674603174603% | Avg. reward: -1725.9583333333333 | Avg. normalized reward: -31.96219135802469 | Avg. agents in deadlock: 28.199404761904763%| LR: 0.006299999999999998

Epoch 140, testing agents on 3: Avg. done agents: 18.536706349206348% | Avg. reward: -1540.0833333333333 | Avg. normalized reward: -28.52006172839506 | Avg. agents in deadlock: 22.197420634920636%| LR: 0.003300000000000003

Epoch 150, testing agents on 3: Avg. done agents: 19.13194444444444% | Avg. reward: -1521.125 | Avg. normalized reward: -28.16898148148148 | Avg. agents in deadlock: 15.843253968253968%| LR: 0.00030000000000000024

Epoch 160, testing agents on 3: Avg. done agents: 18.154761904761905% | Avg. reward: -1556.5 | Avg. normalized reward: -28.824074074074073 | Avg. agents in deadlock: 17.75297619047619%| LR: 0.001349999999999998

Epoch 170, testing agents on 3: Avg. done agents: 21.453373015873016% | Avg. reward: -1515.1666666666667 | Avg. normalized reward: -28.058641975308642 | Avg. agents in deadlock: 13.586309523809522%| LR: 0.0028499999999999992

Epoch 180, testing agents on 3: Avg. done agents: 21.94940476190476% | Avg. reward: -1478.125 | Avg. normalized reward: -27.372685185185187 | Avg. agents in deadlock: 17.75297619047619%| LR: 0.003149999999999999

Epoch 190, testing agents on 3: Avg. done agents: 23.536706349206348% | Avg. reward: -1485.2916666666667 | Avg. normalized reward: -27.505401234567902 | Avg. agents in deadlock: 18.79464285714286%| LR: 0.0016500000000000048

Epoch 200, testing agents on 3: Avg. done agents: 24.826388888888886% | Avg. reward: -1473.9166666666667 | Avg. normalized reward: -27.294753086419753 | Avg. agents in deadlock: 19.836309523809526%| LR: 0.0001499999999999968
