About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 4 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 416
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 4 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 416
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 4 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 416
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 4 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 416
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 4 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 416
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 2 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 408
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 50.124007936507944%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 50.124007936507944%| LR: 0.005

About to train 4 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 416
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 64.21626984126983% | Avg. reward: -771.1666666666666 | Avg. normalized reward: -14.280864197530864 | Avg. agents in deadlock: 14.98015873015873%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 64.21626984126983% | Avg. reward: -771.1666666666666 | Avg. normalized reward: -14.280864197530864 | Avg. agents in deadlock: 14.98015873015873%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 34.06746031746032% | Avg. reward: -1550.3333333333333 | Avg. normalized reward: -28.709876543209877 | Avg. agents in deadlock: 39.55853174603175%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 34.06746031746032% | Avg. reward: -1550.3333333333333 | Avg. normalized reward: -28.709876543209877 | Avg. agents in deadlock: 39.55853174603175%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 6.299603174603174% | Avg. reward: -1719.1666666666667 | Avg. normalized reward: -31.83641975308642 | Avg. agents in deadlock: 58.28373015873015%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 6.299603174603174% | Avg. reward: -1719.1666666666667 | Avg. normalized reward: -31.83641975308642 | Avg. agents in deadlock: 58.28373015873015%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 53.52182539682539%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 6.721230158730158% | Avg. reward: -1716.625 | Avg. normalized reward: -31.78935185185185 | Avg. agents in deadlock: 62.5%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 13.566468253968253% | Avg. reward: -1601.4583333333333 | Avg. normalized reward: -29.656635802469136 | Avg. agents in deadlock: 56.25992063492063%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 13.566468253968253% | Avg. reward: -1601.4583333333333 | Avg. normalized reward: -29.656635802469136 | Avg. agents in deadlock: 56.25992063492063%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 45.01984126984127% | Avg. reward: -1295.5 | Avg. normalized reward: -23.99074074074074 | Avg. agents in deadlock: 44.42460317460317%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 45.01984126984127% | Avg. reward: -1295.5 | Avg. normalized reward: -23.99074074074074 | Avg. agents in deadlock: 44.42460317460317%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 45.01984126984127% | Avg. reward: -1295.5 | Avg. normalized reward: -23.99074074074074 | Avg. agents in deadlock: 44.42460317460317%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 45.01984126984127% | Avg. reward: -1295.5 | Avg. normalized reward: -23.99074074074074 | Avg. agents in deadlock: 44.42460317460317%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 45.01984126984127% | Avg. reward: -1295.5 | Avg. normalized reward: -23.99074074074074 | Avg. agents in deadlock: 44.42460317460317%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 59.58829365079366% | Avg. reward: -892.125 | Avg. normalized reward: -16.520833333333332 | Avg. agents in deadlock: 14.285714285714285%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 35.45634920634921% | Avg. reward: -1395.5416666666667 | Avg. normalized reward: -25.843364197530864 | Avg. agents in deadlock: 31.433531746031747%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 35.45634920634921% | Avg. reward: -1395.5416666666667 | Avg. normalized reward: -25.843364197530864 | Avg. agents in deadlock: 31.433531746031747%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 38.50694444444444% | Avg. reward: -1347.5416666666667 | Avg. normalized reward: -24.954475308641978 | Avg. agents in deadlock: 43.973214285714285%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 38.50694444444444% | Avg. reward: -1347.5416666666667 | Avg. normalized reward: -24.954475308641978 | Avg. agents in deadlock: 43.973214285714285%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 38.50694444444444% | Avg. reward: -1347.5416666666667 | Avg. normalized reward: -24.954475308641978 | Avg. agents in deadlock: 43.973214285714285%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 30.803571428571423% | Avg. reward: -1443.5833333333333 | Avg. normalized reward: -26.733024691358022 | Avg. agents in deadlock: 56.69642857142857%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 30.803571428571423% | Avg. reward: -1443.5833333333333 | Avg. normalized reward: -26.733024691358022 | Avg. agents in deadlock: 56.69642857142857%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 6.884920634920634% | Avg. reward: -1716.875 | Avg. normalized reward: -31.79398148148148 | Avg. agents in deadlock: 62.286706349206355%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 42.604166666666664% | Avg. reward: -1153.1666666666667 | Avg. normalized reward: -21.35493827160494 | Avg. agents in deadlock: 22.32638888888889%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 42.604166666666664% | Avg. reward: -1153.1666666666667 | Avg. normalized reward: -21.35493827160494 | Avg. agents in deadlock: 22.32638888888889%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 68.82440476190474% | Avg. reward: -787.25 | Avg. normalized reward: -14.578703703703704 | Avg. agents in deadlock: 21.800595238095237%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 68.82440476190474% | Avg. reward: -787.25 | Avg. normalized reward: -14.578703703703704 | Avg. agents in deadlock: 21.800595238095237%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 68.82440476190474% | Avg. reward: -787.25 | Avg. normalized reward: -14.578703703703704 | Avg. agents in deadlock: 21.800595238095237%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 61.845238095238095% | Avg. reward: -983.125 | Avg. normalized reward: -18.20601851851852 | Avg. agents in deadlock: 25.178571428571434%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 51.230158730158735% | Avg. reward: -1233.6666666666667 | Avg. normalized reward: -22.84567901234568 | Avg. agents in deadlock: 24.642857142857142%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 51.230158730158735% | Avg. reward: -1233.6666666666667 | Avg. normalized reward: -22.84567901234568 | Avg. agents in deadlock: 24.642857142857142%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 30.625000000000007% | Avg. reward: -1328.2916666666667 | Avg. normalized reward: -24.597993827160494 | Avg. agents in deadlock: 45.53571428571428%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 30.625000000000007% | Avg. reward: -1328.2916666666667 | Avg. normalized reward: -24.597993827160494 | Avg. agents in deadlock: 45.53571428571428%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 63.07539682539682% | Avg. reward: -933.125 | Avg. normalized reward: -17.28009259259259 | Avg. agents in deadlock: 16.974206349206348%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 63.07539682539682% | Avg. reward: -933.125 | Avg. normalized reward: -17.28009259259259 | Avg. agents in deadlock: 16.974206349206348%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 63.07539682539682% | Avg. reward: -933.125 | Avg. normalized reward: -17.28009259259259 | Avg. agents in deadlock: 16.974206349206348%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 63.07539682539682% | Avg. reward: -933.125 | Avg. normalized reward: -17.28009259259259 | Avg. agents in deadlock: 16.974206349206348%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 31.52281746031746% | Avg. reward: -1343.2916666666667 | Avg. normalized reward: -24.875771604938272 | Avg. agents in deadlock: 47.99107142857142%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 31.52281746031746% | Avg. reward: -1343.2916666666667 | Avg. normalized reward: -24.875771604938272 | Avg. agents in deadlock: 47.99107142857142%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 4.4146825396825395% | Avg. reward: -1801.1666666666667 | Avg. normalized reward: -33.35493827160494 | Avg. agents in deadlock: 65.57043650793652%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 4.4146825396825395% | Avg. reward: -1801.1666666666667 | Avg. normalized reward: -33.35493827160494 | Avg. agents in deadlock: 65.57043650793652%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 5.109126984126983% | Avg. reward: -1783.0833333333333 | Avg. normalized reward: -33.02006172839506 | Avg. agents in deadlock: 55.37698412698413%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 35.9077380952381% | Avg. reward: -1209.7083333333333 | Avg. normalized reward: -22.402006172839506 | Avg. agents in deadlock: 19.285714285714285%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 35.9077380952381% | Avg. reward: -1209.7083333333333 | Avg. normalized reward: -22.402006172839506 | Avg. agents in deadlock: 19.285714285714285%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 41.99404761904762% | Avg. reward: -1186.3333333333333 | Avg. normalized reward: -21.969135802469136 | Avg. agents in deadlock: 48.333333333333336%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 41.99404761904762% | Avg. reward: -1186.3333333333333 | Avg. normalized reward: -21.969135802469136 | Avg. agents in deadlock: 48.333333333333336%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 41.99404761904762% | Avg. reward: -1186.3333333333333 | Avg. normalized reward: -21.969135802469136 | Avg. agents in deadlock: 48.333333333333336%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 41.99404761904762% | Avg. reward: -1186.3333333333333 | Avg. normalized reward: -21.969135802469136 | Avg. agents in deadlock: 48.333333333333336%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 41.99404761904762% | Avg. reward: -1186.3333333333333 | Avg. normalized reward: -21.969135802469136 | Avg. agents in deadlock: 48.333333333333336%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 43.05555555555555%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 21.30456349206349% | Avg. reward: -1398.2916666666667 | Avg. normalized reward: -25.89429012345679 | Avg. agents in deadlock: 15.892857142857144%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 46.88988095238094% | Avg. reward: -1186.7083333333333 | Avg. normalized reward: -21.97608024691358 | Avg. agents in deadlock: 32.82242063492063%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 46.88988095238094% | Avg. reward: -1186.7083333333333 | Avg. normalized reward: -21.97608024691358 | Avg. agents in deadlock: 32.82242063492063%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 60.89781746031747%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 32.19742063492064% | Avg. reward: -1274.375 | Avg. normalized reward: -23.599537037037038 | Avg. agents in deadlock: 34.74206349206349%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 13.963293650793648% | Avg. reward: -1669.2916666666667 | Avg. normalized reward: -30.91280864197531 | Avg. agents in deadlock: 48.541666666666664%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 10.803571428571429% | Avg. reward: -1817.2083333333333 | Avg. normalized reward: -33.652006172839506 | Avg. agents in deadlock: 12.5%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 32.06349206349206% | Avg. reward: -1558.0 | Avg. normalized reward: -28.85185185185185 | Avg. agents in deadlock: 19.270833333333336%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 57.16269841269842% | Avg. reward: -1022.25 | Avg. normalized reward: -18.930555555555557 | Avg. agents in deadlock: 26.235119047619044%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 83.33333333333334% | Avg. reward: -470.7916666666667 | Avg. normalized reward: -8.718364197530864 | Avg. agents in deadlock: 12.5%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 83.33333333333334% | Avg. reward: -470.7916666666667 | Avg. normalized reward: -8.718364197530864 | Avg. agents in deadlock: 12.5%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 83.33333333333334% | Avg. reward: -470.7916666666667 | Avg. normalized reward: -8.718364197530864 | Avg. agents in deadlock: 12.5%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 83.33333333333334% | Avg. reward: -470.7916666666667 | Avg. normalized reward: -8.718364197530864 | Avg. agents in deadlock: 12.5%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 82.14285714285715% | Avg. reward: -513.5416666666666 | Avg. normalized reward: -9.51003086419753 | Avg. agents in deadlock: 16.666666666666664%| LR: 0.005


Epoch 60, testing agents on 3: Avg. done agents: 84.6875% | Avg. reward: -447.25 | Avg. normalized reward: -8.282407407407407 | Avg. agents in deadlock: 6.979166666666667%| LR: 0.005


Epoch 70, testing agents on 3: Avg. done agents: 86.77083333333333% | Avg. reward: -451.5416666666667 | Avg. normalized reward: -8.361882716049383 | Avg. agents in deadlock: 6.979166666666667%| LR: 0.005


Epoch 80, testing agents on 3: Avg. done agents: 83.75% | Avg. reward: -504.375 | Avg. normalized reward: -9.340277777777779 | Avg. agents in deadlock: 11.041666666666664%| LR: 0.005


Epoch 90, testing agents on 3: Avg. done agents: 72.49503968253967% | Avg. reward: -834.5833333333334 | Avg. normalized reward: -15.455246913580247 | Avg. agents in deadlock: 16.865079365079364%| LR: 0.005


Epoch 100, testing agents on 3: Avg. done agents: 81.87003968253967% | Avg. reward: -582.2916666666666 | Avg. normalized reward: -10.783179012345679 | Avg. agents in deadlock: 13.368055555555555%| LR: 0.005


Epoch 110, testing agents on 3: Avg. done agents: 80.53075396825396% | Avg. reward: -559.4583333333334 | Avg. normalized reward: -10.36033950617284 | Avg. agents in deadlock: 7.688492063492062%| LR: 0.005


Epoch 120, testing agents on 3: Avg. done agents: 58.96825396825397% | Avg. reward: -889.375 | Avg. normalized reward: -16.46990740740741 | Avg. agents in deadlock: 10.987103174603174%| LR: 0.005


Epoch 130, testing agents on 3: Avg. done agents: 12.986111111111112% | Avg. reward: -1753.7083333333333 | Avg. normalized reward: -32.476080246913575 | Avg. agents in deadlock: 36.17063492063492%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 45.83333333333333%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 45.83333333333333%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 54.166666666666664%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 54.166666666666664%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 60.416666666666664%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 1000
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 8.854166666666668% | Avg. reward: -1848.625 | Avg. normalized reward: -34.2337962962963 | Avg. agents in deadlock: 47.50496031746032%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 8.854166666666668% | Avg. reward: -1848.625 | Avg. normalized reward: -34.2337962962963 | Avg. agents in deadlock: 47.50496031746032%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 31.830357142857142%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 38.83928571428572%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 48.31349206349207%| LR: 0.005


Epoch 60, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 48.31349206349207%| LR: 0.005


Epoch 70, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 48.31349206349207%| LR: 0.005


Epoch 80, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 48.31349206349207%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 20
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
 
Epoch 10, testing agents on 3: Avg. done agents: 0.5208333333333333% | Avg. reward: -1883.4583333333333 | Avg. normalized reward: -34.878858024691354 | Avg. agents in deadlock: 27.142857142857142%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 17.5% | Avg. reward: -1641.5 | Avg. normalized reward: -30.39814814814815 | Avg. agents in deadlock: 48.844246031746025%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 20
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 
Epoch 10, testing agents on 3: Avg. done agents: 38.35813492063492% | Avg. reward: -1383.2916666666667 | Avg. normalized reward: -25.616512345679013 | Avg. agents in deadlock: 46.79067460317461%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 38.35813492063492% | Avg. reward: -1383.2916666666667 | Avg. normalized reward: -25.616512345679013 | Avg. agents in deadlock: 46.79067460317461%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 50
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 512
 
Epoch 10, testing agents on 3: Avg. done agents: 50.297619047619044% | Avg. reward: -1297.1666666666667 | Avg. normalized reward: -24.021604938271608 | Avg. agents in deadlock: 9.375%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 78.58134920634922% | Avg. reward: -690.9166666666666 | Avg. normalized reward: -12.794753086419753 | Avg. agents in deadlock: 12.698412698412698%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 69.72718253968253% | Avg. reward: -739.1666666666666 | Avg. normalized reward: -13.68827160493827 | Avg. agents in deadlock: 14.781746031746032%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 10
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 512
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 10
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 512
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 10
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 512
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 10
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 512
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 
Epoch 10, testing agents on 3: Avg. done agents: 81.84027777777777% | Avg. reward: -610.3333333333334 | Avg. normalized reward: -11.30246913580247 | Avg. agents in deadlock: 14.409722222222223%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 81.84027777777777% | Avg. reward: -610.3333333333334 | Avg. normalized reward: -11.30246913580247 | Avg. agents in deadlock: 14.409722222222223%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 81.84027777777777% | Avg. reward: -610.3333333333334 | Avg. normalized reward: -11.30246913580247 | Avg. agents in deadlock: 14.409722222222223%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 81.84027777777777% | Avg. reward: -610.3333333333334 | Avg. normalized reward: -11.30246913580247 | Avg. agents in deadlock: 14.409722222222223%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 84.81646825396825% | Avg. reward: -526.0416666666666 | Avg. normalized reward: -9.741512345679011 | Avg. agents in deadlock: 11.433531746031745%| LR: 0.005


Epoch 60, testing agents on 3: Avg. done agents: 81.75099206349205% | Avg. reward: -596.875 | Avg. normalized reward: -11.05324074074074 | Avg. agents in deadlock: 11.999007936507937%| LR: 0.005


Epoch 70, testing agents on 3: Avg. done agents: 83.31349206349205% | Avg. reward: -545.5 | Avg. normalized reward: -10.101851851851851 | Avg. agents in deadlock: 10.436507936507937%| LR: 0.005


Epoch 80, testing agents on 3: Avg. done agents: 76.62698412698413% | Avg. reward: -711.5 | Avg. normalized reward: -13.175925925925926 | Avg. agents in deadlock: 4.464285714285714%| LR: 0.005


Epoch 90, testing agents on 3: Avg. done agents: 72.46031746031747% | Avg. reward: -793.125 | Avg. normalized reward: -14.6875 | Avg. agents in deadlock: 7.5892857142857135%| LR: 0.005


Epoch 100, testing agents on 3: Avg. done agents: 71.86507936507937% | Avg. reward: -813.875 | Avg. normalized reward: -15.07175925925926 | Avg. agents in deadlock: 7.5892857142857135%| LR: 0.005


Epoch 110, testing agents on 3: Avg. done agents: 74.99007936507937% | Avg. reward: -758.5416666666666 | Avg. normalized reward: -14.047067901234568 | Avg. agents in deadlock: 4.464285714285714%| LR: 0.005


Epoch 120, testing agents on 3: Avg. done agents: 74.02281746031747% | Avg. reward: -756.0833333333334 | Avg. normalized reward: -14.001543209876544 | Avg. agents in deadlock: 6.547619047619048%| LR: 0.005


Epoch 130, testing agents on 3: Avg. done agents: 76.88988095238095% | Avg. reward: -658.5833333333334 | Avg. normalized reward: -12.195987654320989 | Avg. agents in deadlock: 18.943452380952383%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 128
 
Epoch 10, testing agents on 3: Avg. done agents: 10.019841269841272% | Avg. reward: -1676.1666666666667 | Avg. normalized reward: -31.040123456790123 | Avg. agents in deadlock: 46.25%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 7.415674603174603% | Avg. reward: -1696.4583333333333 | Avg. normalized reward: -31.415895061728392 | Avg. agents in deadlock: 47.8125%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 10.019841269841272% | Avg. reward: -1629.8333333333333 | Avg. normalized reward: -30.182098765432098 | Avg. agents in deadlock: 42.1875%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 20.813492063492063% | Avg. reward: -1522.375 | Avg. normalized reward: -28.19212962962963 | Avg. agents in deadlock: 43.56150793650793%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 40.29761904761904% | Avg. reward: -1326.25 | Avg. normalized reward: -24.560185185185187 | Avg. agents in deadlock: 48.83928571428572%| LR: 0.005


Epoch 60, testing agents on 3: Avg. done agents: 40.0595238095238% | Avg. reward: -1329.5833333333333 | Avg. normalized reward: -24.62191358024691 | Avg. agents in deadlock: 46.33928571428572%| LR: 0.005


Epoch 70, testing agents on 3: Avg. done agents: 40.0595238095238% | Avg. reward: -1329.5833333333333 | Avg. normalized reward: -24.62191358024691 | Avg. agents in deadlock: 46.33928571428572%| LR: 0.005


Epoch 80, testing agents on 3: Avg. done agents: 41.10119047619047% | Avg. reward: -1314.5416666666667 | Avg. normalized reward: -24.343364197530864 | Avg. agents in deadlock: 42.172619047619044%| LR: 0.005


Epoch 90, testing agents on 3: Avg. done agents: 45.267857142857146% | Avg. reward: -1299.125 | Avg. normalized reward: -24.05787037037037 | Avg. agents in deadlock: 42.172619047619044%| LR: 0.005


Epoch 100, testing agents on 3: Avg. done agents: 44.226190476190474% | Avg. reward: -1315.7083333333333 | Avg. normalized reward: -24.36496913580247 | Avg. agents in deadlock: 46.33928571428572%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 
Epoch 10, testing agents on 3: Avg. done agents: 66.73115079365078% | Avg. reward: -976.5833333333334 | Avg. normalized reward: -18.084876543209877 | Avg. agents in deadlock: 32.67361111111111%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 67.32638888888887% | Avg. reward: -961.9166666666666 | Avg. normalized reward: -17.813271604938272 | Avg. agents in deadlock: 32.67361111111111%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 68.51686507936506% | Avg. reward: -928.5416666666666 | Avg. normalized reward: -17.195216049382715 | Avg. agents in deadlock: 31.48313492063492%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 59.72222222222222%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 512
 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 1.0
done_reward: 0
deadlock_reward: -1000
batch_size: 256
 
Epoch 10, testing agents on 3: Avg. done agents: 19.221230158730158% | Avg. reward: -1495.9583333333333 | Avg. normalized reward: -27.70293209876543 | Avg. agents in deadlock: 47.61904761904762%| LR: 0.005


Epoch 20, testing agents on 3: Avg. done agents: 21.30456349206349% | Avg. reward: -1474.6666666666667 | Avg. normalized reward: -27.308641975308642 | Avg. agents in deadlock: 47.61904761904762%| LR: 0.005


Epoch 30, testing agents on 3: Avg. done agents: 20.783730158730158% | Avg. reward: -1468.5416666666667 | Avg. normalized reward: -27.19521604938272 | Avg. agents in deadlock: 47.61904761904762%| LR: 0.005


Epoch 40, testing agents on 3: Avg. done agents: 21.65178571428571% | Avg. reward: -1446.75 | Avg. normalized reward: -26.791666666666668 | Avg. agents in deadlock: 46.230158730158735%| LR: 0.005


Epoch 50, testing agents on 3: Avg. done agents: 20.783730158730158% | Avg. reward: -1461.0416666666667 | Avg. normalized reward: -27.05632716049383 | Avg. agents in deadlock: 47.61904761904762%| LR: 0.005


Epoch 60, testing agents on 3: Avg. done agents: 14.30059523809524% | Avg. reward: -1558.9583333333333 | Avg. normalized reward: -28.869598765432098 | Avg. agents in deadlock: 16.875%| LR: 0.005


Epoch 70, testing agents on 3: Avg. done agents: 55.17857142857142% | Avg. reward: -909.7083333333334 | Avg. normalized reward: -16.846450617283953 | Avg. agents in deadlock: 21.835317460317462%| LR: 0.005


Epoch 80, testing agents on 3: Avg. done agents: 56.403769841269835% | Avg. reward: -883.0416666666666 | Avg. normalized reward: -16.352623456790123 | Avg. agents in deadlock: 17.172619047619044%| LR: 0.005


Epoch 90, testing agents on 3: Avg. done agents: 61.820436507936506% | Avg. reward: -869.8333333333334 | Avg. normalized reward: -16.108024691358025 | Avg. agents in deadlock: 19.672619047619047%| LR: 0.005


Epoch 100, testing agents on 3: Avg. done agents: 59.1468253968254% | Avg. reward: -928.8333333333334 | Avg. normalized reward: -17.200617283950617 | Avg. agents in deadlock: 23.839285714285715%| LR: 0.005


Epoch 110, testing agents on 3: Avg. done agents: 43.621031746031754% | Avg. reward: -1113.75 | Avg. normalized reward: -20.625 | Avg. agents in deadlock: 39.21626984126984%| LR: 0.005


Epoch 120, testing agents on 3: Avg. done agents: 68.7748015873016% | Avg. reward: -720.1666666666666 | Avg. normalized reward: -13.33641975308642 | Avg. agents in deadlock: 19.866071428571427%| LR: 0.005


Epoch 130, testing agents on 3: Avg. done agents: 73.46230158730158% | Avg. reward: -692.5 | Avg. normalized reward: -12.824074074074074 | Avg. agents in deadlock: 19.345238095238095%| LR: 0.005


Epoch 140, testing agents on 3: Avg. done agents: 73.80952380952381% | Avg. reward: -695.2916666666666 | Avg. normalized reward: -12.87577160493827 | Avg. agents in deadlock: 23.511904761904763%| LR: 0.005


Epoch 150, testing agents on 3: Avg. done agents: 77.52976190476191% | Avg. reward: -670.0833333333334 | Avg. normalized reward: -12.408950617283951 | Avg. agents in deadlock: 18.75%| LR: 0.005


Epoch 160, testing agents on 3: Avg. done agents: 68.25396825396827% | Avg. reward: -736.9583333333334 | Avg. normalized reward: -13.647376543209877 | Avg. agents in deadlock: 20.38690476190476%| LR: 0.005


Epoch 170, testing agents on 3: Avg. done agents: 68.25396825396827% | Avg. reward: -737.0 | Avg. normalized reward: -13.648148148148149 | Avg. agents in deadlock: 20.38690476190476%| LR: 0.005


Epoch 180, testing agents on 3: Avg. done agents: 68.25396825396827% | Avg. reward: -736.9583333333334 | Avg. normalized reward: -13.647376543209877 | Avg. agents in deadlock: 20.38690476190476%| LR: 0.005


Epoch 190, testing agents on 3: Avg. done agents: 75.68452380952381% | Avg. reward: -674.9583333333334 | Avg. normalized reward: -12.49922839506173 | Avg. agents in deadlock: 18.511904761904763%| LR: 0.005


Epoch 200, testing agents on 3: Avg. done agents: 64.65277777777777% | Avg. reward: -928.25 | Avg. normalized reward: -17.189814814814813 | Avg. agents in deadlock: 32.66865079365079%| LR: 0.005

About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 78.3184523809524% | Avg. reward: -659.8333333333334 | Avg. normalized reward: -12.219135802469136 | Avg. agents in deadlock: 10.11904761904762%| LR: 0.05

Epoch 20, testing agents on 3: Avg. done agents: 78.3184523809524% | Avg. reward: -659.75 | Avg. normalized reward: -12.217592592592593 | Avg. agents in deadlock: 10.11904761904762%| LR: 0.05

Epoch 30, testing agents on 3: Avg. done agents: 78.3184523809524% | Avg. reward: -659.1666666666666 | Avg. normalized reward: -12.20679012345679 | Avg. agents in deadlock: 10.11904761904762%| LR: 0.025

Epoch 40, testing agents on 3: Avg. done agents: 78.3184523809524% | Avg. reward: -659.1666666666666 | Avg. normalized reward: -12.20679012345679 | Avg. agents in deadlock: 10.11904761904762%| LR: 0.025

Epoch 50, testing agents on 3: Avg. done agents: 75.54067460317461% | Avg. reward: -688.7916666666666 | Avg. normalized reward: -12.7554012345679 | Avg. agents in deadlock: 10.11904761904762%| LR: 0.025

Epoch 60, testing agents on 3: Avg. done agents: 63.24900793650794% | Avg. reward: -1096.75 | Avg. normalized reward: -20.310185185185187 | Avg. agents in deadlock: 20.138888888888893%| LR: 0.0125

Epoch 70, testing agents on 3: Avg. done agents: 19.791666666666664% | Avg. reward: -1838.2916666666667 | Avg. normalized reward: -34.04243827160494 | Avg. agents in deadlock: 39.88095238095238%| LR: 0.0125

Epoch 80, testing agents on 3: Avg. done agents: 8.333333333333332% | Avg. reward: -1860.5416666666667 | Avg. normalized reward: -34.454475308641975 | Avg. agents in deadlock: 31.547619047619047%| LR: 0.00625

Epoch 90, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 24.404761904761905%| LR: 0.00625

Epoch 100, testing agents on 3: Avg. done agents: 24.09722222222222% | Avg. reward: -1780.6666666666667 | Avg. normalized reward: -32.97530864197531 | Avg. agents in deadlock: 30.357142857142854%| LR: 0.00625

Epoch 110, testing agents on 3: Avg. done agents: 19.444444444444446% | Avg. reward: -1831.125 | Avg. normalized reward: -33.90972222222222 | Avg. agents in deadlock: 45.83333333333333%| LR: 0.003125

Epoch 120, testing agents on 3: Avg. done agents: 29.930555555555554% | Avg. reward: -1650.7916666666667 | Avg. normalized reward: -30.57021604938272 | Avg. agents in deadlock: 33.144841269841265%| LR: 0.003125

Epoch 130, testing agents on 3: Avg. done agents: 30.97222222222222% | Avg. reward: -1625.8333333333333 | Avg. normalized reward: -30.108024691358022 | Avg. agents in deadlock: 25.49603174603175%| LR: 0.0015625

Epoch 140, testing agents on 3: Avg. done agents: 30.97222222222222% | Avg. reward: -1628.75 | Avg. normalized reward: -30.162037037037038 | Avg. agents in deadlock: 24.662698412698415%| LR: 0.0015625

Epoch 150, testing agents on 3: Avg. done agents: 27.708333333333336% | Avg. reward: -1695.1666666666667 | Avg. normalized reward: -31.391975308641978 | Avg. agents in deadlock: 23.21428571428571%| LR: 0.0015625

Epoch 160, testing agents on 3: Avg. done agents: 28.40277777777778% | Avg. reward: -1694.625 | Avg. normalized reward: -31.381944444444443 | Avg. agents in deadlock: 29.672619047619047%| LR: 0.00078125
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 11.11111111111111% | Avg. reward: -1746.9583333333333 | Avg. normalized reward: -32.351080246913575 | Avg. agents in deadlock: 50.81845238095239%| LR: 0.05

Epoch 20, testing agents on 3: Avg. done agents: 11.11111111111111% | Avg. reward: -1745.625 | Avg. normalized reward: -32.326388888888886 | Avg. agents in deadlock: 50.81845238095239%| LR: 0.05

Epoch 30, testing agents on 3: Avg. done agents: 11.11111111111111% | Avg. reward: -1745.625 | Avg. normalized reward: -32.326388888888886 | Avg. agents in deadlock: 50.81845238095239%| LR: 0.025

Epoch 40, testing agents on 3: Avg. done agents: 11.11111111111111% | Avg. reward: -1745.625 | Avg. normalized reward: -32.326388888888886 | Avg. agents in deadlock: 50.81845238095239%| LR: 0.025

Epoch 50, testing agents on 3: Avg. done agents: 11.11111111111111% | Avg. reward: -1746.9583333333333 | Avg. normalized reward: -32.351080246913575 | Avg. agents in deadlock: 50.81845238095239%| LR: 0.025

Epoch 60, testing agents on 3: Avg. done agents: 11.11111111111111% | Avg. reward: -1745.625 | Avg. normalized reward: -32.326388888888886 | Avg. agents in deadlock: 50.81845238095239%| LR: 0.0125

Epoch 70, testing agents on 3: Avg. done agents: 11.11111111111111% | Avg. reward: -1745.625 | Avg. normalized reward: -32.326388888888886 | Avg. agents in deadlock: 50.81845238095239%| LR: 0.0125

Epoch 80, testing agents on 3: Avg. done agents: 11.11111111111111% | Avg. reward: -1745.625 | Avg. normalized reward: -32.326388888888886 | Avg. agents in deadlock: 50.81845238095239%| LR: 0.00625

Epoch 90, testing agents on 3: Avg. done agents: 3.125% | Avg. reward: -1856.5 | Avg. normalized reward: -34.379629629629626 | Avg. agents in deadlock: 54.91071428571429%| LR: 0.00625

Epoch 100, testing agents on 3: Avg. done agents: 3.125% | Avg. reward: -1855.1666666666667 | Avg. normalized reward: -34.35493827160494 | Avg. agents in deadlock: 54.91071428571429%| LR: 0.00625

Epoch 110, testing agents on 3: Avg. done agents: 3.125% | Avg. reward: -1856.5 | Avg. normalized reward: -34.379629629629626 | Avg. agents in deadlock: 54.91071428571429%| LR: 0.003125

Epoch 120, testing agents on 3: Avg. done agents: 1.0416666666666665% | Avg. reward: -1886.5416666666667 | Avg. normalized reward: -34.935956790123456 | Avg. agents in deadlock: 54.91071428571429%| LR: 0.003125

Epoch 130, testing agents on 3: Avg. done agents: 1.0416666666666665% | Avg. reward: -1886.5416666666667 | Avg. normalized reward: -34.935956790123456 | Avg. agents in deadlock: 55.952380952380956%| LR: 0.0015625

Epoch 140, testing agents on 3: Avg. done agents: 1.0416666666666665% | Avg. reward: -1886.5416666666667 | Avg. normalized reward: -34.935956790123456 | Avg. agents in deadlock: 55.952380952380956%| LR: 0.0015625
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.1
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 1.736111111111111% | Avg. reward: -1865.375 | Avg. normalized reward: -34.54398148148148 | Avg. agents in deadlock: 55.605158730158735%| LR: 0.1

Epoch 20, testing agents on 3: Avg. done agents: 3.819444444444444% | Avg. reward: -1862.125 | Avg. normalized reward: -34.4837962962963 | Avg. agents in deadlock: 55.605158730158735%| LR: 0.1

Epoch 30, testing agents on 3: Avg. done agents: 3.819444444444444% | Avg. reward: -1859.625 | Avg. normalized reward: -34.4375 | Avg. agents in deadlock: 55.605158730158735%| LR: 0.010000000000000002

Epoch 40, testing agents on 3: Avg. done agents: 2.6785714285714284% | Avg. reward: -1849.7916666666667 | Avg. normalized reward: -34.255401234567906 | Avg. agents in deadlock: 51.78571428571429%| LR: 0.010000000000000002

Epoch 50, testing agents on 3: Avg. done agents: 7.123015873015872% | Avg. reward: -1823.2083333333333 | Avg. normalized reward: -33.76311728395061 | Avg. agents in deadlock: 44.55357142857143%| LR: 0.010000000000000002

Epoch 60, testing agents on 3: Avg. done agents: 7.123015873015872% | Avg. reward: -1813.9583333333333 | Avg. normalized reward: -33.59182098765432 | Avg. agents in deadlock: 42.76785714285714%| LR: 0.0010000000000000002

Epoch 70, testing agents on 3: Avg. done agents: 6.289682539682538% | Avg. reward: -1814.5 | Avg. normalized reward: -33.601851851851855 | Avg. agents in deadlock: 42.76785714285714%| LR: 0.0010000000000000002

Epoch 80, testing agents on 3: Avg. done agents: 5.456349206349206% | Avg. reward: -1815.0833333333333 | Avg. normalized reward: -33.61265432098765 | Avg. agents in deadlock: 43.958333333333336%| LR: 0.00010000000000000003

Epoch 90, testing agents on 3: Avg. done agents: 7.123015873015872% | Avg. reward: -1813.9583333333333 | Avg. normalized reward: -33.59182098765432 | Avg. agents in deadlock: 39.79166666666667%| LR: 0.00010000000000000003
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.1
learning_rate_decay: 0.1
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 11.845238095238097% | Avg. reward: -1786.125 | Avg. normalized reward: -33.076388888888886 | Avg. agents in deadlock: 37.748015873015866%| LR: 0.1

Epoch 20, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 65.89781746031746%| LR: 0.1

Epoch 30, testing agents on 3: Avg. done agents: 65.68452380952381% | Avg. reward: -1017.7083333333334 | Avg. normalized reward: -18.846450617283953 | Avg. agents in deadlock: 13.740079365079364%| LR: 0.010000000000000002

Epoch 40, testing agents on 3: Avg. done agents: 6.498015873015872% | Avg. reward: -1808.75 | Avg. normalized reward: -33.495370370370374 | Avg. agents in deadlock: 11.607142857142856%| LR: 0.010000000000000002

Epoch 50, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 71.52777777777777%| LR: 0.010000000000000002

Epoch 60, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 72.22222222222223%| LR: 0.0010000000000000002

Epoch 70, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 71.52777777777777%| LR: 0.0010000000000000002

Epoch 80, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 72.91666666666666%| LR: 0.00010000000000000003

Epoch 90, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 70.83333333333334%| LR: 0.00010000000000000003
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 41.785714285714285%| LR: 0.005

Epoch 20, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 41.785714285714285%| LR: 0.005

Epoch 30, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 41.785714285714285%| LR: 0.0025

Epoch 40, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 41.785714285714285%| LR: 0.0025

Epoch 50, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 41.785714285714285%| LR: 0.0025

Epoch 60, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 41.785714285714285%| LR: 0.00125

Epoch 70, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 41.785714285714285%| LR: 0.00125

Epoch 80, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 41.785714285714285%| LR: 0.000625

Epoch 90, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 41.785714285714285%| LR: 0.000625

Epoch 100, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 41.785714285714285%| LR: 0.000625

Epoch 110, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 41.785714285714285%| LR: 0.0003125

Epoch 120, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 41.785714285714285%| LR: 0.0003125

Epoch 130, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 41.785714285714285%| LR: 0.00015625

Epoch 140, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 41.785714285714285%| LR: 0.00015625

Epoch 150, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 41.785714285714285%| LR: 0.00015625
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.005
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.01
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.01
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 60.61507936507936% | Avg. reward: -1073.7916666666667 | Avg. normalized reward: -19.88503086419753 | Avg. agents in deadlock: 36.607142857142854%| LR: 0.01

Epoch 20, testing agents on 3: Avg. done agents: 60.09424603174603% | Avg. reward: -1090.375 | Avg. normalized reward: -20.19212962962963 | Avg. agents in deadlock: 37.12797619047619%| LR: 0.01

Epoch 30, testing agents on 3: Avg. done agents: 60.61507936507936% | Avg. reward: -1073.7916666666667 | Avg. normalized reward: -19.88503086419753 | Avg. agents in deadlock: 36.607142857142854%| LR: 0.005

Epoch 40, testing agents on 3: Avg. done agents: 60.09424603174603% | Avg. reward: -1090.375 | Avg. normalized reward: -20.19212962962963 | Avg. agents in deadlock: 37.12797619047619%| LR: 0.005

Epoch 50, testing agents on 3: Avg. done agents: 60.61507936507936% | Avg. reward: -1073.75 | Avg. normalized reward: -19.88425925925926 | Avg. agents in deadlock: 36.607142857142854%| LR: 0.005

Epoch 60, testing agents on 3: Avg. done agents: 60.61507936507936% | Avg. reward: -1073.375 | Avg. normalized reward: -19.877314814814813 | Avg. agents in deadlock: 36.607142857142854%| LR: 0.0025

Epoch 70, testing agents on 3: Avg. done agents: 58.14980158730159% | Avg. reward: -1099.5833333333333 | Avg. normalized reward: -20.36265432098765 | Avg. agents in deadlock: 39.07242063492064%| LR: 0.0025

Epoch 80, testing agents on 3: Avg. done agents: 58.14980158730159% | Avg. reward: -1098.7083333333333 | Avg. normalized reward: -20.34645061728395 | Avg. agents in deadlock: 34.905753968253975%| LR: 0.00125

Epoch 90, testing agents on 3: Avg. done agents: 58.670634920634924% | Avg. reward: -1081.4166666666667 | Avg. normalized reward: -20.026234567901238 | Avg. agents in deadlock: 34.38492063492064%| LR: 0.00125

Epoch 100, testing agents on 3: Avg. done agents: 60.92757936507937% | Avg. reward: -1070.3333333333333 | Avg. normalized reward: -19.820987654320987 | Avg. agents in deadlock: 36.294642857142854%| LR: 0.00125

Epoch 110, testing agents on 3: Avg. done agents: 61.44841269841269% | Avg. reward: -1053.8333333333333 | Avg. normalized reward: -19.51543209876543 | Avg. agents in deadlock: 35.773809523809526%| LR: 0.000625

Epoch 120, testing agents on 3: Avg. done agents: 61.44841269841269% | Avg. reward: -1054.625 | Avg. normalized reward: -19.53009259259259 | Avg. agents in deadlock: 35.773809523809526%| LR: 0.000625

Epoch 130, testing agents on 3: Avg. done agents: 61.44841269841269% | Avg. reward: -1054.3333333333333 | Avg. normalized reward: -19.52469135802469 | Avg. agents in deadlock: 35.773809523809526%| LR: 0.0003125

Epoch 140, testing agents on 3: Avg. done agents: 60.92757936507937% | Avg. reward: -1071.0833333333333 | Avg. normalized reward: -19.834876543209877 | Avg. agents in deadlock: 36.294642857142854%| LR: 0.0003125

Epoch 150, testing agents on 3: Avg. done agents: 61.44841269841269% | Avg. reward: -1053.75 | Avg. normalized reward: -19.51388888888889 | Avg. agents in deadlock: 35.773809523809526%| LR: 0.0003125

Epoch 160, testing agents on 3: Avg. done agents: 60.8531746031746% | Avg. reward: -1070.25 | Avg. normalized reward: -19.819444444444443 | Avg. agents in deadlock: 36.36904761904762%| LR: 0.00015625

Epoch 170, testing agents on 3: Avg. done agents: 60.8531746031746% | Avg. reward: -1070.3333333333333 | Avg. normalized reward: -19.820987654320987 | Avg. agents in deadlock: 36.36904761904762%| LR: 0.00015625

Epoch 180, testing agents on 3: Avg. done agents: 61.37400793650792% | Avg. reward: -1053.6666666666667 | Avg. normalized reward: -19.51234567901235 | Avg. agents in deadlock: 35.84821428571428%| LR: 7.8125e-05

Epoch 190, testing agents on 3: Avg. done agents: 60.33234126984126% | Avg. reward: -1087.5833333333333 | Avg. normalized reward: -20.14043209876543 | Avg. agents in deadlock: 36.88988095238095%| LR: 7.8125e-05

Epoch 200, testing agents on 3: Avg. done agents: 61.44841269841269% | Avg. reward: -1054.5833333333333 | Avg. normalized reward: -19.52932098765432 | Avg. agents in deadlock: 35.773809523809526%| LR: 7.8125e-05

Epoch 210, testing agents on 3: Avg. done agents: 61.969246031746025% | Avg. reward: -1037.25 | Avg. normalized reward: -19.208333333333332 | Avg. agents in deadlock: 35.25297619047619%| LR: 3.90625e-05

Epoch 220, testing agents on 3: Avg. done agents: 60.8531746031746% | Avg. reward: -1070.1666666666667 | Avg. normalized reward: -19.817901234567902 | Avg. agents in deadlock: 36.36904761904762%| LR: 3.90625e-05

Epoch 230, testing agents on 3: Avg. done agents: 60.8531746031746% | Avg. reward: -1070.25 | Avg. normalized reward: -19.819444444444443 | Avg. agents in deadlock: 36.36904761904762%| LR: 1.953125e-05

Epoch 240, testing agents on 3: Avg. done agents: 61.44841269841269% | Avg. reward: -1053.8333333333333 | Avg. normalized reward: -19.51543209876543 | Avg. agents in deadlock: 35.773809523809526%| LR: 1.953125e-05
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.01
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.01
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 300
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.01
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 62.25198412698413%| LR: 0.01

Epoch 20, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 63.39285714285715%| LR: 0.01

Epoch 30, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 55.952380952380956%| LR: 0.005

Epoch 40, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 61.60714285714285%| LR: 0.005

Epoch 50, testing agents on 3: Avg. done agents: 12.5% | Avg. reward: -1834.5833333333333 | Avg. normalized reward: -33.973765432098766 | Avg. agents in deadlock: 65.87301587301587%| LR: 0.005

Epoch 60, testing agents on 3: Avg. done agents: 6.25% | Avg. reward: -1866.2916666666667 | Avg. normalized reward: -34.560956790123456 | Avg. agents in deadlock: 65.87301587301587%| LR: 0.0025

Epoch 70, testing agents on 3: Avg. done agents: 6.25% | Avg. reward: -1866.2916666666667 | Avg. normalized reward: -34.560956790123456 | Avg. agents in deadlock: 65.87301587301587%| LR: 0.0025

Epoch 80, testing agents on 3: Avg. done agents: 13.928571428571429% | Avg. reward: -1803.0416666666667 | Avg. normalized reward: -33.389660493827165 | Avg. agents in deadlock: 65.83333333333333%| LR: 0.00125

Epoch 90, testing agents on 3: Avg. done agents: 16.805555555555554% | Avg. reward: -1789.2916666666667 | Avg. normalized reward: -33.13503086419753 | Avg. agents in deadlock: 62.26190476190477%| LR: 0.00125

Epoch 100, testing agents on 3: Avg. done agents: 19.930555555555554% | Avg. reward: -1756.9583333333333 | Avg. normalized reward: -32.536265432098766 | Avg. agents in deadlock: 61.2202380952381%| LR: 0.00125

Epoch 110, testing agents on 3: Avg. done agents: 19.930555555555554% | Avg. reward: -1756.9583333333333 | Avg. normalized reward: -32.536265432098766 | Avg. agents in deadlock: 61.2202380952381%| LR: 0.000625

Epoch 120, testing agents on 3: Avg. done agents: 18.541666666666668% | Avg. reward: -1770.3333333333333 | Avg. normalized reward: -32.78395061728395 | Avg. agents in deadlock: 61.2202380952381%| LR: 0.000625

Epoch 130, testing agents on 3: Avg. done agents: 18.541666666666668% | Avg. reward: -1770.3333333333333 | Avg. normalized reward: -32.78395061728395 | Avg. agents in deadlock: 61.2202380952381%| LR: 0.0003125

Epoch 140, testing agents on 3: Avg. done agents: 18.541666666666668% | Avg. reward: -1770.3333333333333 | Avg. normalized reward: -32.78395061728395 | Avg. agents in deadlock: 61.2202380952381%| LR: 0.0003125

Epoch 150, testing agents on 3: Avg. done agents: 18.541666666666668% | Avg. reward: -1770.3333333333333 | Avg. normalized reward: -32.78395061728395 | Avg. agents in deadlock: 61.2202380952381%| LR: 0.0003125
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.01
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 58.26388888888888% | Avg. reward: -1118.1666666666667 | Avg. normalized reward: -20.70679012345679 | Avg. agents in deadlock: 32.53472222222222%| LR: 0.009801468428384716

Epoch 20, testing agents on 3: Avg. done agents: 58.26388888888888% | Avg. reward: -1118.1666666666667 | Avg. normalized reward: -20.70679012345679 | Avg. agents in deadlock: 32.53472222222222%| LR: 0.00913540287137281

Epoch 30, testing agents on 3: Avg. done agents: 58.26388888888888% | Avg. reward: -1118.1666666666667 | Avg. normalized reward: -20.70679012345679 | Avg. agents in deadlock: 32.53472222222222%| LR: 0.008064535268264884

Epoch 40, testing agents on 3: Avg. done agents: 57.97619047619047% | Avg. reward: -1170.7916666666667 | Avg. normalized reward: -21.68132716049383 | Avg. agents in deadlock: 36.12103174603174%| LR: 0.00669368960122646

Epoch 50, testing agents on 3: Avg. done agents: 44.75198412698413% | Avg. reward: -1415.6666666666667 | Avg. normalized reward: -26.21604938271605 | Avg. agents in deadlock: 50.68452380952381%| LR: 0.005157053795390645

Epoch 60, testing agents on 3: Avg. done agents: 45.27281746031746% | Avg. reward: -1398.1666666666667 | Avg. normalized reward: -25.891975308641978 | Avg. agents in deadlock: 50.16369047619047%| LR: 0.0036050444698038572

Epoch 70, testing agents on 3: Avg. done agents: 46.66170634920635% | Avg. reward: -1381.625 | Avg. normalized reward: -25.58564814814815 | Avg. agents in deadlock: 48.25396825396825%| LR: 0.002189583110739348

Epoch 80, testing agents on 3: Avg. done agents: 45.620039682539684% | Avg. reward: -1380.625 | Avg. normalized reward: -25.56712962962963 | Avg. agents in deadlock: 49.81646825396825%| LR: 0.0010492249381215486

Epoch 90, testing agents on 3: Avg. done agents: 45.620039682539684% | Avg. reward: -1380.625 | Avg. normalized reward: -25.56712962962963 | Avg. agents in deadlock: 49.81646825396825%| LR: 0.00029559615522887296

Epoch 100, testing agents on 3: Avg. done agents: 45.620039682539684% | Avg. reward: -1380.625 | Avg. normalized reward: -25.56712962962963 | Avg. agents in deadlock: 49.81646825396825%| LR: 2.4671981713420015e-06

Epoch 110, testing agents on 3: Avg. done agents: 44.78670634920635% | Avg. reward: -1396.7083333333333 | Avg. normalized reward: -25.86496913580247 | Avg. agents in deadlock: 50.64980158730158%| LR: 0.0001985315716152841

Epoch 120, testing agents on 3: Avg. done agents: 45.620039682539684% | Avg. reward: -1380.625 | Avg. normalized reward: -25.56712962962963 | Avg. agents in deadlock: 49.81646825396825%| LR: 0.0008645971286271895

Epoch 130, testing agents on 3: Avg. done agents: 45.02480158730158% | Avg. reward: -1397.5 | Avg. normalized reward: -25.87962962962963 | Avg. agents in deadlock: 50.411706349206355%| LR: 0.0019354647317351167

Epoch 140, testing agents on 3: Avg. done agents: 47.59920634920634% | Avg. reward: -1349.125 | Avg. normalized reward: -24.983796296296298 | Avg. agents in deadlock: 48.432539682539684%| LR: 0.003306310398773541

Epoch 150, testing agents on 3: Avg. done agents: 52.88690476190476% | Avg. reward: -1216.6666666666667 | Avg. normalized reward: -22.530864197530864 | Avg. agents in deadlock: 43.144841269841265%| LR: 0.004842946204609355

Epoch 160, testing agents on 3: Avg. done agents: 52.88690476190476% | Avg. reward: -1217.5833333333333 | Avg. normalized reward: -22.54783950617284 | Avg. agents in deadlock: 43.144841269841265%| LR: 0.006394955530196143

Epoch 170, testing agents on 3: Avg. done agents: 49.345238095238095% | Avg. reward: -1281.7083333333333 | Avg. normalized reward: -23.73533950617284 | Avg. agents in deadlock: 45.64484126984127%| LR: 0.00781041688926065

Epoch 180, testing agents on 3: Avg. done agents: 46.58730158730158% | Avg. reward: -1364.5833333333333 | Avg. normalized reward: -25.27006172839506 | Avg. agents in deadlock: 46.76587301587301%| LR: 0.008950775061878446

Epoch 190, testing agents on 3: Avg. done agents: 55.084325396825406% | Avg. reward: -1184.0416666666667 | Avg. normalized reward: -21.9266975308642 | Avg. agents in deadlock: 44.91567460317461%| LR: 0.009704403844771125

Epoch 200, testing agents on 3: Avg. done agents: 53.69543650793651% | Avg. reward: -1201.5833333333333 | Avg. normalized reward: -22.25154320987654 | Avg. agents in deadlock: 46.304563492063494%| LR: 0.009997532801828657
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.01
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 19.583333333333332% | Avg. reward: -1788.4583333333333 | Avg. normalized reward: -33.119598765432094 | Avg. agents in deadlock: 68.6111111111111%| LR: 0.008802029828000156

Epoch 20, testing agents on 3: Avg. done agents: 19.583333333333332% | Avg. reward: -1788.4583333333333 | Avg. normalized reward: -33.119598765432094 | Avg. agents in deadlock: 68.6111111111111%| LR: 0.005392295478639226

Epoch 30, testing agents on 3: Avg. done agents: 19.583333333333332% | Avg. reward: -1788.4583333333333 | Avg. normalized reward: -33.119598765432094 | Avg. agents in deadlock: 68.6111111111111%| LR: 0.0017527597583490825

Epoch 40, testing agents on 3: Avg. done agents: 19.583333333333332% | Avg. reward: -1788.4583333333333 | Avg. normalized reward: -33.119598765432094 | Avg. agents in deadlock: 68.6111111111111%| LR: 1.5413331334360186e-05

Epoch 50, testing agents on 3: Avg. done agents: 19.583333333333332% | Avg. reward: -1788.4583333333333 | Avg. normalized reward: -33.119598765432094 | Avg. agents in deadlock: 68.6111111111111%| LR: 0.0011979701719998864

Epoch 60, testing agents on 3: Avg. done agents: 19.583333333333332% | Avg. reward: -1788.4583333333333 | Avg. normalized reward: -33.119598765432094 | Avg. agents in deadlock: 71.58730158730158%| LR: 0.004607704521360939

Epoch 70, testing agents on 3: Avg. done agents: 1.0416666666666665% | Avg. reward: -1881.7083333333333 | Avg. normalized reward: -34.84645061728395 | Avg. agents in deadlock: 50.376984126984134%| LR: 0.008247240241651218

Epoch 80, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 51.33928571428571%| LR: 0.009984586668666005

Epoch 90, testing agents on 3: Avg. done agents: 17.271825396825395% | Avg. reward: -1643.8333333333333 | Avg. normalized reward: -30.441358024691358 | Avg. agents in deadlock: 40.550595238095234%| LR: 0.008802029828000477

Epoch 100, testing agents on 3: Avg. done agents: 42.57440476190475% | Avg. reward: -1341.7083333333333 | Avg. normalized reward: -24.84645061728395 | Avg. agents in deadlock: 28.35813492063492%| LR: 0.005392295478639422

Epoch 110, testing agents on 3: Avg. done agents: 34.53373015873016% | Avg. reward: -1484.7916666666667 | Avg. normalized reward: -27.496141975308642 | Avg. agents in deadlock: 24.78174603174603%| LR: 0.0017527597583491526

Epoch 120, testing agents on 3: Avg. done agents: 38.70039682539683% | Avg. reward: -1453.3333333333333 | Avg. normalized reward: -26.91358024691358 | Avg. agents in deadlock: 24.78174603174603%| LR: 1.5413331334360752e-05

Epoch 130, testing agents on 3: Avg. done agents: 34.53373015873016% | Avg. reward: -1484.7916666666667 | Avg. normalized reward: -27.496141975308642 | Avg. agents in deadlock: 24.78174603174603%| LR: 0.0011979701719998452

Epoch 140, testing agents on 3: Avg. done agents: 36.61706349206349% | Avg. reward: -1469.0833333333333 | Avg. normalized reward: -27.205246913580247 | Avg. agents in deadlock: 24.78174603174603%| LR: 0.00460770452136077

Epoch 150, testing agents on 3: Avg. done agents: 33.23412698412698% | Avg. reward: -1549.625 | Avg. normalized reward: -28.69675925925926 | Avg. agents in deadlock: 34.13194444444444%| LR: 0.00824724024165092

Epoch 160, testing agents on 3: Avg. done agents: 34.623015873015866% | Avg. reward: -1532.4166666666667 | Avg. normalized reward: -28.37808641975309 | Avg. agents in deadlock: 43.25396825396825%| LR: 0.009984586668665639

Epoch 170, testing agents on 3: Avg. done agents: 18.44246031746032% | Avg. reward: -1754.625 | Avg. normalized reward: -32.49305555555556 | Avg. agents in deadlock: 54.960317460317455%| LR: 0.008802029828000156

Epoch 180, testing agents on 3: Avg. done agents: 18.44246031746032% | Avg. reward: -1754.625 | Avg. normalized reward: -32.49305555555556 | Avg. agents in deadlock: 63.24404761904761%| LR: 0.005392295478639221

Epoch 190, testing agents on 3: Avg. done agents: 18.44246031746032% | Avg. reward: -1754.625 | Avg. normalized reward: -32.49305555555556 | Avg. agents in deadlock: 61.855158730158735%| LR: 0.001752759758349082
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.05
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 60.06944444444444% | Avg. reward: -956.5416666666666 | Avg. normalized reward: -17.713734567901234 | Avg. agents in deadlock: 17.311507936507933%| LR: 0.04401014914000077

Epoch 20, testing agents on 3: Avg. done agents: 60.06944444444444% | Avg. reward: -956.5416666666666 | Avg. normalized reward: -17.713734567901234 | Avg. agents in deadlock: 17.311507936507933%| LR: 0.026961477393196123

Epoch 30, testing agents on 3: Avg. done agents: 60.06944444444444% | Avg. reward: -956.5416666666666 | Avg. normalized reward: -17.713734567901234 | Avg. agents in deadlock: 17.311507936507933%| LR: 0.00876379879174541

Epoch 40, testing agents on 3: Avg. done agents: 60.06944444444444% | Avg. reward: -956.5416666666666 | Avg. normalized reward: -17.713734567901234 | Avg. agents in deadlock: 17.311507936507933%| LR: 7.70666566718009e-05

Epoch 50, testing agents on 3: Avg. done agents: 60.06944444444444% | Avg. reward: -956.5416666666666 | Avg. normalized reward: -17.713734567901234 | Avg. agents in deadlock: 17.311507936507933%| LR: 0.005989850859999431

Epoch 60, testing agents on 3: Avg. done agents: 54.67261904761905% | Avg. reward: -1065.8333333333333 | Avg. normalized reward: -19.73765432098765 | Avg. agents in deadlock: 21.23015873015873%| LR: 0.023038522606804685

Epoch 70, testing agents on 3: Avg. done agents: 68.25396825396824% | Avg. reward: -922.7083333333334 | Avg. normalized reward: -17.087191358024693 | Avg. agents in deadlock: 19.692460317460316%| LR: 0.041236201208256065

Epoch 80, testing agents on 3: Avg. done agents: 50.78373015873016% | Avg. reward: -1203.3333333333333 | Avg. normalized reward: -22.28395061728395 | Avg. agents in deadlock: 24.384920634920636%| LR: 0.04992293334332999

Epoch 90, testing agents on 3: Avg. done agents: 54.13690476190476% | Avg. reward: -1123.6666666666667 | Avg. normalized reward: -20.808641975308642 | Avg. agents in deadlock: 18.82936507936508%| LR: 0.04401014914000235

Epoch 100, testing agents on 3: Avg. done agents: 55.0595238095238% | Avg. reward: -1122.5833333333333 | Avg. normalized reward: -20.78858024691358 | Avg. agents in deadlock: 22.400793650793652%| LR: 0.02696147739319709

Epoch 110, testing agents on 3: Avg. done agents: 55.0595238095238% | Avg. reward: -1120.1666666666667 | Avg. normalized reward: -20.74382716049383 | Avg. agents in deadlock: 22.400793650793652%| LR: 0.008763798791745755

Epoch 120, testing agents on 3: Avg. done agents: 66.62202380952381% | Avg. reward: -897.375 | Avg. normalized reward: -16.618055555555557 | Avg. agents in deadlock: 21.67162698412698%| LR: 7.706665667180368e-05

Epoch 130, testing agents on 3: Avg. done agents: 66.62202380952381% | Avg. reward: -897.375 | Avg. normalized reward: -16.618055555555557 | Avg. agents in deadlock: 21.67162698412698%| LR: 0.005989850859999228

Epoch 140, testing agents on 3: Avg. done agents: 66.62202380952381% | Avg. reward: -897.375 | Avg. normalized reward: -16.618055555555557 | Avg. agents in deadlock: 21.67162698412698%| LR: 0.023038522606803866

Epoch 150, testing agents on 3: Avg. done agents: 75.06944444444444% | Avg. reward: -769.5 | Avg. normalized reward: -14.25 | Avg. agents in deadlock: 9.424603174603174%| LR: 0.04123620120825462

Epoch 160, testing agents on 3: Avg. done agents: 7.569444444444444% | Avg. reward: -1784.3333333333333 | Avg. normalized reward: -33.04320987654321 | Avg. agents in deadlock: 49.47916666666667%| LR: 0.049922933343328216

Epoch 170, testing agents on 3: Avg. done agents: 19.275793650793652% | Avg. reward: -1644.6666666666667 | Avg. normalized reward: -30.45679012345679 | Avg. agents in deadlock: 25.86309523809524%| LR: 0.04401014914000078

Epoch 180, testing agents on 3: Avg. done agents: 17.886904761904766% | Avg. reward: -1676.0833333333333 | Avg. normalized reward: -31.03858024691358 | Avg. agents in deadlock: 25.86309523809524%| LR: 0.026961477393196105

Epoch 190, testing agents on 3: Avg. done agents: 17.886904761904766% | Avg. reward: -1676.0833333333333 | Avg. normalized reward: -31.03858024691358 | Avg. agents in deadlock: 25.86309523809524%| LR: 0.008763798791745412

Epoch 200, testing agents on 3: Avg. done agents: 17.886904761904766% | Avg. reward: -1676.0833333333333 | Avg. normalized reward: -31.03858024691358 | Avg. agents in deadlock: 25.86309523809524%| LR: 7.706665667179811e-05
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 47.16269841269842% | Avg. reward: -1387.625 | Avg. normalized reward: -25.69675925925926 | Avg. agents in deadlock: 25.0%| LR: 0.01760405965600031
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 6.0813492063492065% | Avg. reward: -1800.9166666666667 | Avg. normalized reward: -33.35030864197531 | Avg. agents in deadlock: 51.33928571428571%| LR: 0.01760405965600031

Epoch 20, testing agents on 3: Avg. done agents: 36.32936507936507% | Avg. reward: -1531.7916666666667 | Avg. normalized reward: -28.366512345679013 | Avg. agents in deadlock: 45.912698412698404%| LR: 0.010784590957278453

Epoch 30, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 67.3611111111111%| LR: 0.003505519516698165

Epoch 40, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 66.17063492063492%| LR: 3.082666266872037e-05

Epoch 50, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 62.003968253968246%| LR: 0.0023959403439997727

Epoch 60, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 62.5%| LR: 0.009215409042721877

Epoch 70, testing agents on 3: Avg. done agents: 33.417658730158735% | Avg. reward: -1548.25 | Avg. normalized reward: -28.671296296296298 | Avg. agents in deadlock: 51.106150793650784%| LR: 0.016494480483302435

Epoch 80, testing agents on 3: Avg. done agents: 0.5952380952380952% | Avg. reward: -1881.1666666666667 | Avg. normalized reward: -34.836419753086425 | Avg. agents in deadlock: 29.166666666666668%| LR: 0.01996917333733201

Epoch 90, testing agents on 3: Avg. done agents: 48.55158730158731% | Avg. reward: -1325.4583333333333 | Avg. normalized reward: -24.545524691358022 | Avg. agents in deadlock: 34.444444444444436%| LR: 0.017604059656000953

Epoch 100, testing agents on 3: Avg. done agents: 50.30257936507937% | Avg. reward: -1295.625 | Avg. normalized reward: -23.993055555555557 | Avg. agents in deadlock: 33.14980158730159%| LR: 0.010784590957278843

Epoch 110, testing agents on 3: Avg. done agents: 48.51686507936508% | Avg. reward: -1347.5833333333333 | Avg. normalized reward: -24.955246913580247 | Avg. agents in deadlock: 37.31646825396826%| LR: 0.003505519516698305

Epoch 120, testing agents on 3: Avg. done agents: 46.00694444444444% | Avg. reward: -1450.4583333333333 | Avg. normalized reward: -26.86033950617284 | Avg. agents in deadlock: 42.604166666666664%| LR: 3.0826662668721504e-05

Epoch 130, testing agents on 3: Avg. done agents: 46.00694444444444% | Avg. reward: -1450.4583333333333 | Avg. normalized reward: -26.86033950617284 | Avg. agents in deadlock: 46.770833333333336%| LR: 0.0023959403439996903

Epoch 140, testing agents on 3: Avg. done agents: 41.230158730158735% | Avg. reward: -1484.7083333333333 | Avg. normalized reward: -27.494598765432098 | Avg. agents in deadlock: 37.58928571428572%| LR: 0.00921540904272154

Epoch 150, testing agents on 3: Avg. done agents: 38.79960317460318% | Avg. reward: -1531.4166666666667 | Avg. normalized reward: -28.35956790123457 | Avg. agents in deadlock: 46.26984126984126%| LR: 0.01649448048330184

Epoch 160, testing agents on 3: Avg. done agents: 38.105158730158735% | Avg. reward: -1554.75 | Avg. normalized reward: -28.791666666666668 | Avg. agents in deadlock: 42.797619047619044%| LR: 0.019969173337331277

Epoch 170, testing agents on 3: Avg. done agents: 33.035714285714285% | Avg. reward: -1593.4583333333333 | Avg. normalized reward: -29.508487654320987 | Avg. agents in deadlock: 49.32539682539682%| LR: 0.01760405965600031

Epoch 180, testing agents on 3: Avg. done agents: 29.960317460317466% | Avg. reward: -1510.5 | Avg. normalized reward: -27.97222222222222 | Avg. agents in deadlock: 40.09920634920635%| LR: 0.010784590957278442

Epoch 190, testing agents on 3: Avg. done agents: 6.3392857142857135% | Avg. reward: -1779.75 | Avg. normalized reward: -32.958333333333336 | Avg. agents in deadlock: 47.81746031746031%| LR: 0.003505519516698164

Epoch 200, testing agents on 3: Avg. done agents: 5.992063492063491% | Avg. reward: -1765.25 | Avg. normalized reward: -32.68981481481482 | Avg. agents in deadlock: 51.98412698412699%| LR: 3.0826662668719254e-05
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 64 
Epoch 10, testing agents on 3: Avg. done agents: 65.83829365079366% | Avg. reward: -1014.8333333333334 | Avg. normalized reward: -18.793209876543212 | Avg. agents in deadlock: 25.71428571428572%| LR: 0.01760405965600031

Epoch 20, testing agents on 3: Avg. done agents: 65.83829365079366% | Avg. reward: -1014.8333333333334 | Avg. normalized reward: -18.793209876543212 | Avg. agents in deadlock: 25.71428571428572%| LR: 0.010784590957278453

Epoch 30, testing agents on 3: Avg. done agents: 65.83829365079366% | Avg. reward: -1014.8333333333334 | Avg. normalized reward: -18.793209876543212 | Avg. agents in deadlock: 25.71428571428572%| LR: 0.003505519516698165

Epoch 40, testing agents on 3: Avg. done agents: 65.83829365079366% | Avg. reward: -1014.8333333333334 | Avg. normalized reward: -18.793209876543212 | Avg. agents in deadlock: 25.71428571428572%| LR: 3.082666266872037e-05

Epoch 50, testing agents on 3: Avg. done agents: 65.83829365079366% | Avg. reward: -1014.8333333333334 | Avg. normalized reward: -18.793209876543212 | Avg. agents in deadlock: 25.71428571428572%| LR: 0.0023959403439997727

Epoch 60, testing agents on 3: Avg. done agents: 65.83829365079366% | Avg. reward: -1014.8333333333334 | Avg. normalized reward: -18.793209876543212 | Avg. agents in deadlock: 25.71428571428572%| LR: 0.009215409042721877

Epoch 70, testing agents on 3: Avg. done agents: 65.83829365079366% | Avg. reward: -1014.8333333333334 | Avg. normalized reward: -18.793209876543212 | Avg. agents in deadlock: 25.71428571428572%| LR: 0.016494480483302435

Epoch 80, testing agents on 3: Avg. done agents: 65.83829365079366% | Avg. reward: -1014.8333333333334 | Avg. normalized reward: -18.793209876543212 | Avg. agents in deadlock: 25.71428571428572%| LR: 0.01996917333733201

Epoch 90, testing agents on 3: Avg. done agents: 65.83829365079366% | Avg. reward: -1014.8333333333334 | Avg. normalized reward: -18.793209876543212 | Avg. agents in deadlock: 25.71428571428572%| LR: 0.017604059656000953

Epoch 100, testing agents on 3: Avg. done agents: 65.83829365079366% | Avg. reward: -1014.8333333333334 | Avg. normalized reward: -18.793209876543212 | Avg. agents in deadlock: 25.71428571428572%| LR: 0.010784590957278843

Epoch 110, testing agents on 3: Avg. done agents: 65.83829365079366% | Avg. reward: -1014.8333333333334 | Avg. normalized reward: -18.793209876543212 | Avg. agents in deadlock: 25.71428571428572%| LR: 0.003505519516698305

Epoch 120, testing agents on 3: Avg. done agents: 65.83829365079366% | Avg. reward: -1014.8333333333334 | Avg. normalized reward: -18.793209876543212 | Avg. agents in deadlock: 25.71428571428572%| LR: 3.0826662668721504e-05

Epoch 130, testing agents on 3: Avg. done agents: 65.83829365079366% | Avg. reward: -1014.8333333333334 | Avg. normalized reward: -18.793209876543212 | Avg. agents in deadlock: 25.71428571428572%| LR: 0.0023959403439996903

Epoch 140, testing agents on 3: Avg. done agents: 65.83829365079366% | Avg. reward: -1014.8333333333334 | Avg. normalized reward: -18.793209876543212 | Avg. agents in deadlock: 25.71428571428572%| LR: 0.00921540904272154

Epoch 150, testing agents on 3: Avg. done agents: 65.83829365079366% | Avg. reward: -1014.8333333333334 | Avg. normalized reward: -18.793209876543212 | Avg. agents in deadlock: 25.71428571428572%| LR: 0.01649448048330184

Epoch 160, testing agents on 3: Avg. done agents: 65.83829365079366% | Avg. reward: -1014.8333333333334 | Avg. normalized reward: -18.793209876543212 | Avg. agents in deadlock: 25.71428571428572%| LR: 0.019969173337331277

Epoch 170, testing agents on 3: Avg. done agents: 66.43849206349206% | Avg. reward: -934.0 | Avg. normalized reward: -17.296296296296298 | Avg. agents in deadlock: 23.21428571428571%| LR: 0.01760405965600031

Epoch 180, testing agents on 3: Avg. done agents: 66.43849206349206% | Avg. reward: -934.0 | Avg. normalized reward: -17.296296296296298 | Avg. agents in deadlock: 23.21428571428571%| LR: 0.010784590957278442

Epoch 190, testing agents on 3: Avg. done agents: 66.43849206349206% | Avg. reward: -934.0 | Avg. normalized reward: -17.296296296296298 | Avg. agents in deadlock: 23.21428571428571%| LR: 0.003505519516698164

Epoch 200, testing agents on 3: Avg. done agents: 66.43849206349206% | Avg. reward: -934.0 | Avg. normalized reward: -17.296296296296298 | Avg. agents in deadlock: 23.21428571428571%| LR: 3.0826662668719254e-05
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 80.00992063492063% | Avg. reward: -641.5 | Avg. normalized reward: -11.87962962962963 | Avg. agents in deadlock: 14.434523809523808%| LR: 0.01760405965600031
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 58.869047619047606% | Avg. reward: -1139.5 | Avg. normalized reward: -21.10185185185185 | Avg. agents in deadlock: 35.74900793650793%| LR: 0.01760405965600031
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 42.74305555555556% | Avg. reward: -1482.1666666666667 | Avg. normalized reward: -27.44753086419753 | Avg. agents in deadlock: 20.654761904761905%| LR: 0.01760405965600031

Epoch 20, testing agents on 3: Avg. done agents: 34.176587301587304% | Avg. reward: -1445.1666666666667 | Avg. normalized reward: -26.76234567901235 | Avg. agents in deadlock: 26.61706349206349%| LR: 0.010784590957278453

Epoch 30, testing agents on 3: Avg. done agents: 43.99801587301588% | Avg. reward: -1255.6666666666667 | Avg. normalized reward: -23.25308641975309 | Avg. agents in deadlock: 22.22222222222222%| LR: 0.003505519516698165

Epoch 40, testing agents on 3: Avg. done agents: 43.55158730158731% | Avg. reward: -1253.5416666666667 | Avg. normalized reward: -23.213734567901238 | Avg. agents in deadlock: 19.246031746031743%| LR: 3.082666266872037e-05

Epoch 50, testing agents on 3: Avg. done agents: 43.55158730158731% | Avg. reward: -1253.5416666666667 | Avg. normalized reward: -23.213734567901238 | Avg. agents in deadlock: 19.246031746031743%| LR: 0.0023959403439997727

Epoch 60, testing agents on 3: Avg. done agents: 51.20039682539683% | Avg. reward: -1154.7083333333333 | Avg. normalized reward: -21.383487654320987 | Avg. agents in deadlock: 28.621031746031743%| LR: 0.009215409042721877

Epoch 70, testing agents on 3: Avg. done agents: 52.589285714285715% | Avg. reward: -1166.75 | Avg. normalized reward: -21.60648148148148 | Avg. agents in deadlock: 28.621031746031743%| LR: 0.016494480483302435

Epoch 80, testing agents on 3: Avg. done agents: 26.706349206349213% | Avg. reward: -1596.4583333333333 | Avg. normalized reward: -29.56404320987654 | Avg. agents in deadlock: 54.841269841269835%| LR: 0.01996917333733201

Epoch 90, testing agents on 3: Avg. done agents: 49.68253968253968% | Avg. reward: -1361.8333333333333 | Avg. normalized reward: -25.219135802469136 | Avg. agents in deadlock: 47.93650793650793%| LR: 0.017604059656000953

Epoch 100, testing agents on 3: Avg. done agents: 47.896825396825385% | Avg. reward: -1407.625 | Avg. normalized reward: -26.06712962962963 | Avg. agents in deadlock: 47.063492063492056%| LR: 0.010784590957278843

Epoch 110, testing agents on 3: Avg. done agents: 45.29761904761904% | Avg. reward: -1407.5 | Avg. normalized reward: -26.064814814814813 | Avg. agents in deadlock: 48.154761904761905%| LR: 0.003505519516698305

Epoch 120, testing agents on 3: Avg. done agents: 43.2142857142857% | Avg. reward: -1423.7083333333333 | Avg. normalized reward: -26.36496913580247 | Avg. agents in deadlock: 48.154761904761905%| LR: 3.0826662668721504e-05

Epoch 130, testing agents on 3: Avg. done agents: 33.99801587301588% | Avg. reward: -1532.4166666666667 | Avg. normalized reward: -28.37808641975309 | Avg. agents in deadlock: 48.988095238095234%| LR: 0.0023959403439996903

Epoch 140, testing agents on 3: Avg. done agents: 32.99603174603175% | Avg. reward: -1511.5 | Avg. normalized reward: -27.99074074074074 | Avg. agents in deadlock: 41.041666666666664%| LR: 0.00921540904272154

Epoch 150, testing agents on 3: Avg. done agents: 3.472222222222222% | Avg. reward: -1853.9583333333333 | Avg. normalized reward: -34.33256172839506 | Avg. agents in deadlock: 53.29861111111111%| LR: 0.01649448048330184

Epoch 160, testing agents on 3: Avg. done agents: 8.333333333333332% | Avg. reward: -1786.2916666666667 | Avg. normalized reward: -33.079475308641975 | Avg. agents in deadlock: 62.39583333333333%| LR: 0.019969173337331277

Epoch 170, testing agents on 3: Avg. done agents: 7.569444444444444% | Avg. reward: -1786.0 | Avg. normalized reward: -33.074074074074076 | Avg. agents in deadlock: 49.47916666666667%| LR: 0.01760405965600031

Epoch 180, testing agents on 3: Avg. done agents: 27.023809523809522% | Avg. reward: -1643.0833333333333 | Avg. normalized reward: -30.42746913580247 | Avg. agents in deadlock: 51.68650793650793%| LR: 0.010784590957278442

Epoch 190, testing agents on 3: Avg. done agents: 29.980158730158728% | Avg. reward: -1581.4166666666667 | Avg. normalized reward: -29.285493827160494 | Avg. agents in deadlock: 52.480158730158735%| LR: 0.003505519516698164

Epoch 200, testing agents on 3: Avg. done agents: 28.799603174603178% | Avg. reward: -1609.625 | Avg. normalized reward: -29.80787037037037 | Avg. agents in deadlock: 50.74404761904761%| LR: 3.0826662668719254e-05
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.01
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 48.874007936507944% | Avg. reward: -1334.9583333333333 | Avg. normalized reward: -24.72145061728395 | Avg. agents in deadlock: 19.642857142857142%| LR: 0.008802029828000156
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.01
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 57.64880952380952% | Avg. reward: -1156.7916666666667 | Avg. normalized reward: -21.42206790123457 | Avg. agents in deadlock: 28.35813492063492%| LR: 0.008802029828000156

Epoch 20, testing agents on 3: Avg. done agents: 57.64880952380952% | Avg. reward: -1156.7916666666667 | Avg. normalized reward: -21.42206790123457 | Avg. agents in deadlock: 28.35813492063492%| LR: 0.005392295478639226
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.01
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 27.361111111111107% | Avg. reward: -1692.875 | Avg. normalized reward: -31.349537037037038 | Avg. agents in deadlock: 37.26190476190476%| LR: 0.008802029828000156

Epoch 20, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 23.80952380952381%| LR: 0.005392295478639226

Epoch 30, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 23.80952380952381%| LR: 0.0017527597583490825

Epoch 40, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 23.80952380952381%| LR: 1.5413331334360186e-05

Epoch 50, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 23.80952380952381%| LR: 0.0011979701719998864

Epoch 60, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 23.80952380952381%| LR: 0.004607704521360939

Epoch 70, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 23.80952380952381%| LR: 0.008247240241651218

Epoch 80, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 23.80952380952381%| LR: 0.009984586668666005

Epoch 90, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 23.80952380952381%| LR: 0.008802029828000477

Epoch 100, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 23.80952380952381%| LR: 0.005392295478639422

Epoch 110, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 23.80952380952381%| LR: 0.0017527597583491526

Epoch 120, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 23.80952380952381%| LR: 1.5413331334360752e-05

Epoch 130, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 23.80952380952381%| LR: 0.0011979701719998452

Epoch 140, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 23.80952380952381%| LR: 0.00460770452136077

Epoch 150, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 32.142857142857146%| LR: 0.00824724024165092

Epoch 160, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 32.142857142857146%| LR: 0.009984586668665639

Epoch 170, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 42.55952380952381%| LR: 0.008802029828000156

Epoch 180, testing agents on 3: Avg. done agents: 6.527777777777777% | Avg. reward: -1816.5833333333333 | Avg. normalized reward: -33.64043209876543 | Avg. agents in deadlock: 43.79960317460318%| LR: 0.005392295478639221

Epoch 190, testing agents on 3: Avg. done agents: 6.527777777777777% | Avg. reward: -1816.5833333333333 | Avg. normalized reward: -33.64043209876543 | Avg. agents in deadlock: 43.79960317460318%| LR: 0.001752759758349082

Epoch 200, testing agents on 3: Avg. done agents: 6.527777777777777% | Avg. reward: -1816.5833333333333 | Avg. normalized reward: -33.64043209876543 | Avg. agents in deadlock: 43.79960317460318%| LR: 1.5413331334359627e-05
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 48.03075396825396% | Avg. reward: -1402.0416666666667 | Avg. normalized reward: -25.963734567901238 | Avg. agents in deadlock: 39.270833333333336%| LR: 0.019900236577165567

Epoch 20, testing agents on 3: Avg. done agents: 48.03075396825396% | Avg. reward: -1402.0416666666667 | Avg. normalized reward: -25.963734567901238 | Avg. agents in deadlock: 39.270833333333336%| LR: 0.01955793014798329

Epoch 30, testing agents on 3: Avg. done agents: 48.03075396825396% | Avg. reward: -1402.0416666666667 | Avg. normalized reward: -25.963734567901238 | Avg. agents in deadlock: 39.270833333333336%| LR: 0.018980275757606142

Epoch 40, testing agents on 3: Avg. done agents: 45.17361111111111% | Avg. reward: -1470.875 | Avg. normalized reward: -27.238425925925927 | Avg. agents in deadlock: 40.461309523809526%| LR: 0.01818149717425022

Epoch 50, testing agents on 3: Avg. done agents: 40.49107142857142% | Avg. reward: -1521.0833333333333 | Avg. normalized reward: -28.16820987654321 | Avg. agents in deadlock: 47.157738095238095%| LR: 0.01718126297763187

Epoch 60, testing agents on 3: Avg. done agents: 2.7777777777777777% | Avg. reward: -1869.3333333333333 | Avg. normalized reward: -34.617283950617285 | Avg. agents in deadlock: 45.83333333333333%| LR: 0.016004202253258822

Epoch 70, testing agents on 3: Avg. done agents: 8.859126984126984% | Avg. reward: -1772.5416666666667 | Avg. normalized reward: -32.82484567901235 | Avg. agents in deadlock: 44.032738095238095%| LR: 0.014679298142605723

Epoch 80, testing agents on 3: Avg. done agents: 16.999007936507937% | Avg. reward: -1628.25 | Avg. normalized reward: -30.15277777777778 | Avg. agents in deadlock: 44.032738095238095%| LR: 0.013239174181981487

Epoch 90, testing agents on 3: Avg. done agents: 21.860119047619044% | Avg. reward: -1579.5833333333333 | Avg. normalized reward: -29.25154320987654 | Avg. agents in deadlock: 44.032738095238095%| LR: 0.01171929100279409

Epoch 100, testing agents on 3: Avg. done agents: 14.915674603174603% | Avg. reward: -1644.3333333333333 | Avg. normalized reward: -30.450617283950617 | Avg. agents in deadlock: 44.032738095238095%| LR: 0.010157073173118201

Epoch 110, testing agents on 3: Avg. done agents: 10.868055555555555% | Avg. reward: -1756.5 | Avg. normalized reward: -32.52777777777778 | Avg. agents in deadlock: 43.4375%| LR: 0.008590987680624171

Epoch 120, testing agents on 3: Avg. done agents: 14.320436507936506% | Avg. reward: -1660.75 | Avg. normalized reward: -30.75462962962963 | Avg. agents in deadlock: 44.032738095238095%| LR: 0.00705959674767696

Epoch 130, testing agents on 3: Avg. done agents: 14.618055555555557% | Avg. reward: -1694.0833333333333 | Avg. normalized reward: -31.37191358024691 | Avg. agents in deadlock: 46.413690476190474%| LR: 0.005600608301440847

Epoch 140, testing agents on 3: Avg. done agents: 18.958333333333332% | Avg. reward: -1661.125 | Avg. normalized reward: -30.761574074074073 | Avg. agents in deadlock: 46.413690476190474%| LR: 0.004249947479567214

Epoch 150, testing agents on 3: Avg. done agents: 21.33928571428571% | Avg. reward: -1595.6666666666667 | Avg. normalized reward: -29.549382716049383 | Avg. agents in deadlock: 44.032738095238095%| LR: 0.003040872034076857

Epoch 160, testing agents on 3: Avg. done agents: 21.33928571428571% | Avg. reward: -1595.6666666666667 | Avg. normalized reward: -29.549382716049383 | Avg. agents in deadlock: 44.032738095238095%| LR: 0.002003153415129094

Epoch 170, testing agents on 3: Avg. done agents: 18.561507936507937% | Avg. reward: -1628.5416666666667 | Avg. normalized reward: -30.15817901234568 | Avg. agents in deadlock: 44.032738095238095%| LR: 0.0011623436991130653

Epoch 180, testing agents on 3: Avg. done agents: 18.561507936507937% | Avg. reward: -1628.5416666666667 | Avg. normalized reward: -30.15817901234568 | Avg. agents in deadlock: 44.032738095238095%| LR: 0.0005391464117245469

Epoch 190, testing agents on 3: Avg. done agents: 18.561507936507937% | Avg. reward: -1628.5416666666667 | Avg. normalized reward: -30.15817901234568 | Avg. agents in deadlock: 44.032738095238095%| LR: 0.00014890673845226128

Epoch 200, testing agents on 3: Avg. done agents: 18.561507936507937% | Avg. reward: -1628.5416666666667 | Avg. normalized reward: -30.15817901234568 | Avg. agents in deadlock: 44.032738095238095%| LR: 1.2336751833941225e-06
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 0.8333333333333334% | Avg. reward: -1884.2083333333333 | Avg. normalized reward: -34.89274691358025 | Avg. agents in deadlock: 50.96230158730158%| LR: 0.005275000000000002

Epoch 20, testing agents on 3: Avg. done agents: 42.62400793650793% | Avg. reward: -1452.75 | Avg. normalized reward: -26.90277777777778 | Avg. agents in deadlock: 47.772817460317455%| LR: 0.010025000000000003

Epoch 30, testing agents on 3: Avg. done agents: 28.859126984126988% | Avg. reward: -1690.125 | Avg. normalized reward: -31.29861111111111 | Avg. agents in deadlock: 46.42857142857142%| LR: 0.014775

Epoch 40, testing agents on 3: Avg. done agents: 51.80555555555556% | Avg. reward: -1265.0 | Avg. normalized reward: -23.425925925925927 | Avg. agents in deadlock: 33.31349206349206%| LR: 0.019525

Epoch 50, testing agents on 3: Avg. done agents: 50.615079365079374% | Avg. reward: -1296.5833333333333 | Avg. normalized reward: -24.0108024691358 | Avg. agents in deadlock: 38.07539682539682%| LR: 0.015725

Epoch 60, testing agents on 3: Avg. done agents: 51.731150793650805% | Avg. reward: -1262.9583333333333 | Avg. normalized reward: -23.388117283950617 | Avg. agents in deadlock: 36.9593253968254%| LR: 0.010974999999999999

Epoch 70, testing agents on 3: Avg. done agents: 54.508928571428584% | Avg. reward: -1231.7916666666667 | Avg. normalized reward: -22.81095679012346 | Avg. agents in deadlock: 36.9593253968254%| LR: 0.006224999999999998

Epoch 80, testing agents on 3: Avg. done agents: 53.98809523809525% | Avg. reward: -1248.2916666666667 | Avg. normalized reward: -23.116512345679013 | Avg. agents in deadlock: 37.48015873015873%| LR: 0.0014749999999999984

Epoch 90, testing agents on 3: Avg. done agents: 52.79761904761905% | Avg. reward: -1281.8333333333333 | Avg. normalized reward: -23.73765432098765 | Avg. agents in deadlock: 38.670634920634924%| LR: 0.0031374999999999966

Epoch 100, testing agents on 3: Avg. done agents: 45.91269841269842% | Avg. reward: -1397.0 | Avg. normalized reward: -25.87037037037037 | Avg. agents in deadlock: 41.94444444444444%| LR: 0.005512499999999997

Epoch 110, testing agents on 3: Avg. done agents: 45.07936507936508% | Avg. reward: -1413.25 | Avg. normalized reward: -26.171296296296298 | Avg. agents in deadlock: 41.94444444444444%| LR: 0.007887499999999995

Epoch 120, testing agents on 3: Avg. done agents: 47.02876984126985% | Avg. reward: -1364.4166666666667 | Avg. normalized reward: -25.266975308641978 | Avg. agents in deadlock: 40.59027777777778%| LR: 0.010262499999999997

Epoch 130, testing agents on 3: Avg. done agents: 42.822420634920626% | Avg. reward: -1464.5416666666667 | Avg. normalized reward: -27.121141975308642 | Avg. agents in deadlock: 41.67162698412699%| LR: 0.008362500000000004

Epoch 140, testing agents on 3: Avg. done agents: 44.98015873015873% | Avg. reward: -1413.4583333333333 | Avg. normalized reward: -26.17515432098765 | Avg. agents in deadlock: 39.960317460317455%| LR: 0.005987500000000003

Epoch 150, testing agents on 3: Avg. done agents: 38.616071428571416% | Avg. reward: -1529.0 | Avg. normalized reward: -28.314814814814813 | Avg. agents in deadlock: 42.504960317460316%| LR: 0.0036125000000000033

Epoch 160, testing agents on 3: Avg. done agents: 41.393849206349195% | Avg. reward: -1497.8333333333333 | Avg. normalized reward: -27.73765432098765 | Avg. agents in deadlock: 42.504960317460316%| LR: 0.0012375000000000034

Epoch 170, testing agents on 3: Avg. done agents: 41.393849206349195% | Avg. reward: -1499.1666666666667 | Avg. normalized reward: -27.76234567901235 | Avg. agents in deadlock: 42.504960317460316%| LR: 0.0020687499999999985

Epoch 180, testing agents on 3: Avg. done agents: 40.56051587301586% | Avg. reward: -1514.4583333333333 | Avg. normalized reward: -28.045524691358022 | Avg. agents in deadlock: 45.004960317460316%| LR: 0.0032562499999999983

Epoch 190, testing agents on 3: Avg. done agents: 41.393849206349195% | Avg. reward: -1500.5833333333333 | Avg. normalized reward: -27.78858024691358 | Avg. agents in deadlock: 42.504960317460316%| LR: 0.004443749999999998

Epoch 200, testing agents on 3: Avg. done agents: 41.393849206349195% | Avg. reward: -1500.5833333333333 | Avg. normalized reward: -27.78858024691358 | Avg. agents in deadlock: 42.504960317460316%| LR: 0.005631249999999998
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 44.662698412698404% | Avg. reward: -1403.3333333333333 | Avg. normalized reward: -25.98765432098765 | Avg. agents in deadlock: 48.69047619047619%| LR: 0.007199999999999998
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 61.78075396825397%| LR: 0.007199999999999998

Epoch 20, testing agents on 3: Avg. done agents: 0.0% | Avg. reward: -1897.5 | Avg. normalized reward: -35.138888888888886 | Avg. agents in deadlock: 67.70833333333334%| LR: 0.015199999999999997

Epoch 30, testing agents on 3: Avg. done agents: 1.3888888888888888% | Avg. reward: -1881.0416666666667 | Avg. normalized reward: -34.83410493827161 | Avg. agents in deadlock: 37.37599206349206%| LR: 0.0168

Epoch 40, testing agents on 3: Avg. done agents: 8.090277777777777% | Avg. reward: -1767.8333333333333 | Avg. normalized reward: -32.73765432098765 | Avg. agents in deadlock: 31.150793650793656%| LR: 0.008799999999999999

Epoch 50, testing agents on 3: Avg. done agents: 21.398809523809526% | Avg. reward: -1640.4166666666667 | Avg. normalized reward: -30.37808641975309 | Avg. agents in deadlock: 35.19345238095238%| LR: 0.0008000000000000007

Epoch 60, testing agents on 3: Avg. done agents: 4.965277777777778% | Avg. reward: -1816.0833333333333 | Avg. normalized reward: -33.63117283950617 | Avg. agents in deadlock: 31.25%| LR: 0.0035999999999999943

Epoch 70, testing agents on 3: Avg. done agents: 4.3055555555555545% | Avg. reward: -1859.25 | Avg. normalized reward: -34.43055555555556 | Avg. agents in deadlock: 32.93650793650794%| LR: 0.007599999999999998

Epoch 80, testing agents on 3: Avg. done agents: 2.083333333333333% | Avg. reward: -1878.375 | Avg. normalized reward: -34.78472222222222 | Avg. agents in deadlock: 31.770833333333332%| LR: 0.0084

Epoch 90, testing agents on 3: Avg. done agents: 1.3888888888888888% | Avg. reward: -1883.2083333333333 | Avg. normalized reward: -34.87422839506173 | Avg. agents in deadlock: 40.10416666666667%| LR: 0.004399999999999995

Epoch 100, testing agents on 3: Avg. done agents: 5.902777777777777% | Avg. reward: -1816.4583333333333 | Avg. normalized reward: -33.63811728395061 | Avg. agents in deadlock: 30.828373015873016%| LR: 0.00040000000000000034

Epoch 110, testing agents on 3: Avg. done agents: 5.902777777777777% | Avg. reward: -1816.4583333333333 | Avg. normalized reward: -33.63811728395061 | Avg. agents in deadlock: 33.80456349206349%| LR: 0.0018000000000000017

Epoch 120, testing agents on 3: Avg. done agents: 7.569444444444444% | Avg. reward: -1784.1666666666667 | Avg. normalized reward: -33.04012345679013 | Avg. agents in deadlock: 35.91269841269842%| LR: 0.003799999999999999

Epoch 130, testing agents on 3: Avg. done agents: 8.090277777777777% | Avg. reward: -1767.75 | Avg. normalized reward: -32.736111111111114 | Avg. agents in deadlock: 32.142857142857146%| LR: 0.0042

Epoch 140, testing agents on 3: Avg. done agents: 8.090277777777777% | Avg. reward: -1767.75 | Avg. normalized reward: -32.736111111111114 | Avg. agents in deadlock: 30.679563492063487%| LR: 0.002200000000000002

Epoch 150, testing agents on 3: Avg. done agents: 8.090277777777777% | Avg. reward: -1767.75 | Avg. normalized reward: -32.736111111111114 | Avg. agents in deadlock: 30.679563492063487%| LR: 0.00020000000000000017

Epoch 160, testing agents on 3: Avg. done agents: 8.090277777777777% | Avg. reward: -1767.75 | Avg. normalized reward: -32.736111111111114 | Avg. agents in deadlock: 32.06845238095238%| LR: 0.0008999999999999986

Epoch 170, testing agents on 3: Avg. done agents: 8.090277777777777% | Avg. reward: -1767.75 | Avg. normalized reward: -32.736111111111114 | Avg. agents in deadlock: 28.422619047619047%| LR: 0.0018999999999999996

Epoch 180, testing agents on 3: Avg. done agents: 8.090277777777777% | Avg. reward: -1767.9166666666667 | Avg. normalized reward: -32.739197530864196 | Avg. agents in deadlock: 31.547619047619047%| LR: 0.0021

Epoch 190, testing agents on 3: Avg. done agents: 8.090277777777777% | Avg. reward: -1767.75 | Avg. normalized reward: -32.736111111111114 | Avg. agents in deadlock: 32.589285714285715%| LR: 0.0011000000000000033

Epoch 200, testing agents on 3: Avg. done agents: 7.04861111111111% | Avg. reward: -1784.875 | Avg. normalized reward: -33.05324074074074 | Avg. agents in deadlock: 34.672619047619044%| LR: 9.999999999999788e-05
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 
Epoch 10, testing agents on 3: Avg. done agents: 32.25694444444444% | Avg. reward: -1642.0416666666667 | Avg. normalized reward: -30.40817901234568 | Avg. agents in deadlock: 47.19742063492063%| LR: 0.007199999999999998

Epoch 20, testing agents on 3: Avg. done agents: 32.25694444444444% | Avg. reward: -1642.0416666666667 | Avg. normalized reward: -30.40817901234568 | Avg. agents in deadlock: 47.19742063492063%| LR: 0.015199999999999997

Epoch 30, testing agents on 3: Avg. done agents: 32.25694444444444% | Avg. reward: -1642.0416666666667 | Avg. normalized reward: -30.40817901234568 | Avg. agents in deadlock: 47.19742063492063%| LR: 0.0168

Epoch 40, testing agents on 3: Avg. done agents: 39.78174603174604% | Avg. reward: -1480.6666666666667 | Avg. normalized reward: -27.419753086419753 | Avg. agents in deadlock: 29.74702380952381%| LR: 0.008799999999999999

Epoch 50, testing agents on 3: Avg. done agents: 54.49404761904761% | Avg. reward: -1235.75 | Avg. normalized reward: -22.88425925925926 | Avg. agents in deadlock: 22.604166666666668%| LR: 0.0008000000000000007

Epoch 60, testing agents on 3: Avg. done agents: 56.92460317460317% | Avg. reward: -1204.1666666666667 | Avg. normalized reward: -22.299382716049383 | Avg. agents in deadlock: 21.5625%| LR: 0.0035999999999999943

Epoch 70, testing agents on 3: Avg. done agents: 56.44345238095239% | Avg. reward: -1220.0 | Avg. normalized reward: -22.59259259259259 | Avg. agents in deadlock: 35.91765873015873%| LR: 0.007599999999999998

Epoch 80, testing agents on 3: Avg. done agents: 51.254960317460316% | Avg. reward: -1352.75 | Avg. normalized reward: -25.050925925925927 | Avg. agents in deadlock: 41.800595238095234%| LR: 0.0084

Epoch 90, testing agents on 3: Avg. done agents: 53.43749999999999% | Avg. reward: -1284.9583333333333 | Avg. normalized reward: -23.795524691358022 | Avg. agents in deadlock: 35.25297619047619%| LR: 0.004399999999999995

Epoch 100, testing agents on 3: Avg. done agents: 58.72519841269842% | Avg. reward: -1152.9583333333333 | Avg. normalized reward: -21.35108024691358 | Avg. agents in deadlock: 29.96527777777778%| LR: 0.00040000000000000034

Epoch 110, testing agents on 3: Avg. done agents: 58.72519841269842% | Avg. reward: -1152.9583333333333 | Avg. normalized reward: -21.35108024691358 | Avg. agents in deadlock: 32.94146825396825%| LR: 0.0018000000000000017

Epoch 120, testing agents on 3: Avg. done agents: 52.916666666666664% | Avg. reward: -1301.625 | Avg. normalized reward: -24.104166666666668 | Avg. agents in deadlock: 35.773809523809526%| LR: 0.003799999999999999

Epoch 130, testing agents on 3: Avg. done agents: 49.791666666666664% | Avg. reward: -1350.625 | Avg. normalized reward: -25.011574074074073 | Avg. agents in deadlock: 35.773809523809526%| LR: 0.0042

Epoch 140, testing agents on 3: Avg. done agents: 49.791666666666664% | Avg. reward: -1350.625 | Avg. normalized reward: -25.011574074074073 | Avg. agents in deadlock: 35.773809523809526%| LR: 0.002200000000000002

Epoch 150, testing agents on 3: Avg. done agents: 49.791666666666664% | Avg. reward: -1350.625 | Avg. normalized reward: -25.011574074074073 | Avg. agents in deadlock: 35.773809523809526%| LR: 0.00020000000000000017

Epoch 160, testing agents on 3: Avg. done agents: 49.791666666666664% | Avg. reward: -1350.625 | Avg. normalized reward: -25.011574074074073 | Avg. agents in deadlock: 35.773809523809526%| LR: 0.0008999999999999986

Epoch 170, testing agents on 3: Avg. done agents: 49.791666666666664% | Avg. reward: -1350.625 | Avg. normalized reward: -25.011574074074073 | Avg. agents in deadlock: 35.773809523809526%| LR: 0.0018999999999999996

Epoch 180, testing agents on 3: Avg. done agents: 49.791666666666664% | Avg. reward: -1350.625 | Avg. normalized reward: -25.011574074074073 | Avg. agents in deadlock: 35.773809523809526%| LR: 0.0021

Epoch 190, testing agents on 3: Avg. done agents: 55.07936507936508% | Avg. reward: -1218.625 | Avg. normalized reward: -22.56712962962963 | Avg. agents in deadlock: 30.486111111111107%| LR: 0.0011000000000000033

Epoch 200, testing agents on 3: Avg. done agents: 55.07936507936508% | Avg. reward: -1218.625 | Avg. normalized reward: -22.56712962962963 | Avg. agents in deadlock: 30.486111111111107%| LR: 9.999999999999788e-05
About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 128 About to train 1 agents on (25,25) env.
Parameters:
max_num_cities: 2
max_rails_between_cities: 2
max_rails_in_city: 4
malfunction_rate: 0
max_duration: 50
min_duration: 20
num_episodes: 200
starting from episode: 0
max_steps: 404
eps_initial: 1
eps_decay_rate: 0.999
learning_rate: 0.02
learning_rate_decay: 0.5
done_reward: 0
deadlock_reward: -1000
batch_size: 64 